{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseDir = os.path.join(\"/home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputPath = os.path.join(\"chris\",\"distributed_system\",'millionsong.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = os.path.join(baseDir, inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPartitions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = sc.textFile(fileName, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2001.0,0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPoints = rawData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6724\n"
     ]
    }
   ],
   "source": [
    "print numPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplePoints = rawData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'2001.0,0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817', u'2001.0,0.854411946129,0.604124786151,0.593634078776,0.495885413963,0.266307830936,0.261472105188,0.506387076327,0.464453565511,0.665798573683,0.542968988766,0.58044428577,0.445219373624', u'2001.0,0.908982970575,0.632063159227,0.557428975183,0.498263761394,0.276396052336,0.312809861625,0.448530069406,0.448674249968,0.649791323916,0.489868662682,0.591908113534,0.4500023818', u'2001.0,0.842525219898,0.561826888508,0.508715259692,0.443531142139,0.296733836002,0.250213568176,0.488540873206,0.360508747659,0.575435243185,0.361005878554,0.678378718617,0.409036786173', u'2001.0,0.909303285534,0.653607720915,0.585580794716,0.473250503005,0.251417011835,0.326976795524,0.40432273022,0.371154511756,0.629401917965,0.482243251755,0.566901413923,0.463373691946']\n"
     ]
    }
   ],
   "source": [
    "print samplePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "from test_helper import Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817] 2001.0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "def parsePoint(line):\n",
    "    \"\"\"Converts a comma separated unicode string into a `LabeledPoint`.\n",
    "\n",
    "    Args:\n",
    "        line (unicode): Comma separated unicode string where the first element is the label and the\n",
    "            remaining elements are features.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\n",
    "            features.\n",
    "    \"\"\"\n",
    "    tokens = line.split(',')\n",
    "    label, features = tokens[0], tokens[1:]\n",
    "    return LabeledPoint(label, features)\n",
    "\n",
    "parseSamplePoints = [parsePoint(line) for line in samplePoints]\n",
    "firstPointFeatures = parseSamplePoints[0].features\n",
    "firstPointLabel = parseSamplePoints[0].label\n",
    "print firstPointFeatures, firstPointLabel\n",
    "\n",
    "d = len(firstPointFeatures)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(isinstance(firstPointLabel, float), 'label must be a float')\n",
    "expectedX0 = [0.8841,0.6105,0.6005,0.4747,0.2472,0.3573,0.3441,0.3396,0.6009,0.4257,0.6049,0.4192]\n",
    "Test.assertTrue(np.allclose(expectedX0, firstPointFeatures, 1e-4, 1e-4),\n",
    "                'incorrect features for firstPointFeatures')\n",
    "Test.assertTrue(np.allclose(2001.0, firstPointLabel), 'incorrect label for firstPointLabel')\n",
    "Test.assertTrue(d == 12, 'incorrect number of features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "sampleMorePoints = rawData.take(50)\n",
    "# You can uncomment the line below to see randomly selected features.  These will be randomly\n",
    "# selected each time you run the cell.  Note that you should run this cell with the line commented\n",
    "# out when answering the lab quiz questions.\n",
    "# sampleMorePoints = rawData.takeSample(False, 50)\n",
    "\n",
    "parsedSampleMorePoints = map(parsePoint, sampleMorePoints)\n",
    "dataValues = map(lambda lp: lp.features.toArray(), parsedSampleMorePoints)\n",
    "\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0):\n",
    "    \"\"\"Template for generating the plot layout.\"\"\"\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generate layout and plot\n",
    "fig, ax = preparePlot(np.arange(.5, 11, 1), np.arange(.5, 49, 1), figsize=(8,7), hideLabels=True,\n",
    "                      gridColor='#eeeeee', gridWidth=1.1)\n",
    "image = plt.imshow(dataValues,interpolation='nearest', aspect='auto', cmap=cm.Greys)\n",
    "for x, y, s in zip(np.arange(-.125, 12, 1), np.repeat(-.75, 12), [str(x) for x in range(12)]):\n",
    "    plt.text(x, y, s, color='#999999', size='10')\n",
    "plt.text(4.7, -3, 'Feature', color='#999999', size='11'), ax.set_ylabel('Observation')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011.0 1922.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "parsedDataInit = rawData.map(parsePoint)\n",
    "onlyLabels = parsedDataInit.map(lambda a: a.label).collect()\n",
    "minYear = min(onlyLabels)\n",
    "maxYear = max(onlyLabels)\n",
    "print maxYear, minYear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(len(parsedDataInit.take(1)[0].features), 12,\n",
    "\n",
    "                  'unexpected number of features in sample point')\n",
    "\n",
    "sumFeatTwo = parsedDataInit.map(lambda lp: lp.features[2]).sum()\n",
    "\n",
    "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedDataInit has unexpected values')\n",
    "\n",
    "yearRange = maxYear - minYear\n",
    "\n",
    "Test.assertTrue(yearRange == 89, 'incorrect range for minYear to maxYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.regression.LabeledPoint'>\n",
      "\n",
      "[LabeledPoint(79.0, [0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817])]\n"
     ]
    }
   ],
   "source": [
    "parsedData = parsedDataInit.map(lambda a: LabeledPoint(a.label - minYear,a.features))\n",
    "\n",
    "# Should be a LabeledPoint\n",
    "print type(parsedData.take(1)[0])\n",
    "# View the first point\n",
    "print '\\n{0}'.format(parsedData.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "oldSampleFeatures = parsedDataInit.take(1)[0].features\n",
    "newSampleFeatures = parsedData.take(1)[0].features\n",
    "Test.assertTrue(np.allclose(oldSampleFeatures, newSampleFeatures),\n",
    "                'new features do not match old features')\n",
    "sumFeatTwo = parsedData.map(lambda lp: lp.features[2]).sum()\n",
    "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedData has unexpected values')\n",
    "minYearNew = parsedData.map(lambda lp: lp.label).min()\n",
    "maxYearNew = parsedData.map(lambda lp: lp.label).max()\n",
    "Test.assertTrue(minYearNew == 0, 'incorrect min year in shifted data')\n",
    "Test.assertTrue(maxYearNew == 89, 'incorrect max year in shifted data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get data for plot\n",
    "oldData = (parsedDataInit\n",
    "           .map(lambda lp: (lp.label, 1))\n",
    "           .reduceByKey(lambda x, y: x + y)\n",
    "           .collect())\n",
    "x, y = zip(*oldData)\n",
    "\n",
    "# generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(1920, 2050, 20), np.arange(0, 150, 20))\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "ax.set_xlabel('Year'), ax.set_ylabel('Count')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newData = (parsedData\n",
    "           .map(lambda lp: (lp.label, 1))\n",
    "           .reduceByKey(lambda x, y: x + y)\n",
    "           .collect())\n",
    "x, y = zip(*newData)\n",
    "\n",
    "# generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "ax.set_xlabel('Year (shifted)'), ax.set_ylabel('Count')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5371 682 671 6724\n",
      "6724\n"
     ]
    }
   ],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedData.randomSplit(weights,seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "parsedTestData.cache()\n",
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "nTest = parsedTestData.count()\n",
    "\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print parsedData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Training, validation, and test sets (1e)\n",
    "Test.assertEquals(parsedTrainData.getNumPartitions(), numPartitions,\n",
    "                  'parsedTrainData has wrong number of partitions')\n",
    "Test.assertEquals(parsedValData.getNumPartitions(), numPartitions,\n",
    "                  'parsedValData has wrong number of partitions')\n",
    "Test.assertEquals(parsedTestData.getNumPartitions(), numPartitions,\n",
    "                  'parsedTestData has wrong number of partitions')\n",
    "Test.assertEquals(len(parsedTrainData.take(1)[0].features), 12,\n",
    "                  'parsedTrainData has wrong number of features')\n",
    "sumFeatTwo = (parsedTrainData\n",
    "              .map(lambda lp: lp.features[2])\n",
    "              .sum())\n",
    "sumFeatThree = (parsedValData\n",
    "                .map(lambda lp: lp.features[3])\n",
    "                .reduce(lambda x, y: x + y))\n",
    "sumFeatFour = (parsedTestData\n",
    "               .map(lambda lp: lp.features[4])\n",
    "               .reduce(lambda x, y: x + y))\n",
    "Test.assertTrue(np.allclose([sumFeatTwo, sumFeatThree, sumFeatFour],\n",
    "                            2526.87757656, 297.340394298, 184.235876654),\n",
    "                'parsed Train, Val, Test data has unexpected values')\n",
    "Test.assertTrue(nTrain + nVal + nTest == 6724, 'unexpected Train, Val, Test data set size')\n",
    "Test.assertEquals(nTrain, 5371, 'unexpected value for nTrain')\n",
    "Test.assertEquals(nVal, 682, 'unexpected value for nVal')\n",
    "Test.assertEquals(nTest, 671, 'unexpected value for nTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.9316700801\n"
     ]
    }
   ],
   "source": [
    "averageTrainYear = (parsedTrainData\n",
    "                    .map(lambda a: a.label)\n",
    "                    .mean())\n",
    "print averageTrainYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(averageTrainYear, 53.9316700801),\n",
    "                'incorrect value for averageTrainYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29099444874\n"
     ]
    }
   ],
   "source": [
    "def squaredError(label, prediction):\n",
    "    \"\"\"Calculates the the squared error for a single prediction.\n",
    "\n",
    "    Args:\n",
    "        label (float): The correct value for this observation.\n",
    "        prediction (float): The predicted value for this observation.\n",
    "\n",
    "    Returns:\n",
    "        float: The difference between the `label` and `prediction` squared.\n",
    "    \"\"\"\n",
    "    return (label - prediction)**2\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    \"\"\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\n",
    "\n",
    "    Args:\n",
    "        labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "    return np.sqrt(labelsAndPreds.map(lambda a: squaredError(a[0],a[1])).mean())\n",
    "\n",
    "labelsAndPreds = sc.parallelize([(3., 1.), (1., 2.), (2., 2.)])\n",
    "# RMSE = sqrt[((3-1)^2 + (1-2)^2 + (2-2)^2) / 3] = 1.291\n",
    "exampleRMSE = calcRMSE(labelsAndPreds)\n",
    "print exampleRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(squaredError(3, 1), 4.), 'incorrect definition of squaredError')\n",
    "Test.assertTrue(np.allclose(exampleRMSE, 1.29099444874), 'incorrect value for exampleRMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train RMSE = 21.306\n",
      "Baseline Validation RMSE = 21.586\n",
      "Baseline Test RMSE = 22.137\n"
     ]
    }
   ],
   "source": [
    "labelsAndPredsTrain = parsedTrainData.map(lambda a:(a.label, averageTrainYear))\n",
    "rmseTrainBase = calcRMSE(labelsAndPredsTrain)\n",
    "\n",
    "labelsAndPredsVal = parsedValData.map(lambda a:(a.label, averageTrainYear))\n",
    "rmseValBase = calcRMSE(labelsAndPredsVal)\n",
    "\n",
    "labelsAndPredsTest = parsedTestData.map(lambda a:(a.label, averageTrainYear))\n",
    "rmseTestBase = calcRMSE(labelsAndPredsTest)\n",
    "\n",
    "print 'Baseline Train RMSE = {0:.3f}'.format(rmseTrainBase)\n",
    "print 'Baseline Validation RMSE = {0:.3f}'.format(rmseValBase)\n",
    "print 'Baseline Test RMSE = {0:.3f}'.format(rmseTestBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.0,6.0,24.0]\n",
      "[1.7304,-5.1912,-2.5956]\n"
     ]
    }
   ],
   "source": [
    "def gradientSummand(weights, lp):\n",
    "    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\n",
    "\n",
    "    Note:\n",
    "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
    "        within this function.  For example, they both implement the `dot` method.\n",
    "\n",
    "    Args:\n",
    "        weights (DenseVector): An array of model weights (betas).\n",
    "        lp (LabeledPoint): The `LabeledPoint` for a single observation.\n",
    "\n",
    "    Returns:\n",
    "        DenseVector: An array of values the same length as `weights`.  The gradient summand.\n",
    "    \"\"\"\n",
    "    return (weights.dot(lp.features) - lp.label)*lp.features\n",
    "\n",
    "exampleW = DenseVector([1, 1, 1])\n",
    "exampleLP = LabeledPoint(2.0, [3, 1, 4])\n",
    "# gradientSummand = (dot([1 1 1], [3 1 4]) - 2) * [3 1 4] = (8 - 2) * [3 1 4] = [18 6 24]\n",
    "summandOne = gradientSummand(exampleW, exampleLP)\n",
    "print summandOne\n",
    "\n",
    "exampleW = DenseVector([.24, 1.2, -1.4])\n",
    "exampleLP = LabeledPoint(3.0, [-1.4, 4.2, 2.1])\n",
    "summandTwo = gradientSummand(exampleW, exampleLP)\n",
    "print summandTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(summandOne, [18., 6., 24.]), 'incorrect value for summandOne')\n",
    "Test.assertTrue(np.allclose(summandTwo, [1.7304,-5.1912,-2.5956]), 'incorrect value for summandTwo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.0, 1.75), (1.5, 1.25)]\n"
     ]
    }
   ],
   "source": [
    "def getLabeledPrediction(weights, observation):\n",
    "    \"\"\"Calculates predictions and returns a (label, prediction) tuple.\n",
    "\n",
    "    Note:\n",
    "        The labels should remain unchanged as we'll use this information to calculate prediction\n",
    "        error later.\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): An array with one weight for each features in `trainData`.\n",
    "        observation (LabeledPoint): A `LabeledPoint` that contain the correct label and the\n",
    "            features for the data point.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A (label, prediction) tuple.\n",
    "    \"\"\"\n",
    "    return (observation.label,weights.dot(observation.features))\n",
    "\n",
    "weights = np.array([1.0, 1.5])\n",
    "predictionExample = sc.parallelize([LabeledPoint(2, np.array([1.0, .5])),\n",
    "                                    LabeledPoint(1.5, np.array([.5, .5]))])\n",
    "labelsAndPredsExample = predictionExample.map(lambda lp: getLabeledPrediction(weights, lp))\n",
    "print labelsAndPredsExample.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(labelsAndPredsExample.collect(), [(2.0, 1.75), (1.5, 1.25)],\n",
    "                  'incorrect definition for getLabeledPredictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(79.0, [0.884123733793,0.610454259079,0.600498416968]), LabeledPoint(79.0, [0.854411946129,0.604124786151,0.593634078776])]\n",
      "[ 48.88110449  36.01144093  30.25350092]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def linregGradientDescent(trainData, numIters):\n",
    "    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n",
    "\n",
    "    Note:\n",
    "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
    "        within this function.  For example, they both implement the `dot` method.\n",
    "\n",
    "    Args:\n",
    "        trainData (RDD of LabeledPoint): The labeled data for use in training the model.\n",
    "        numIters (int): The number of iterations of gradient descent to perform.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): A tuple of (weights, training errors).  Weights will be the\n",
    "            final weights (one weight per feature) for the model, and training errors will contain\n",
    "            an error (RMSE) for each iteration of the algorithm.\n",
    "    \"\"\"\n",
    "    # The length of the training data\n",
    "    n = trainData.count()\n",
    "    # The number of features in the training data\n",
    "    d = len(trainData.take(1)[0].features)\n",
    "    w = np.zeros(d)\n",
    "    alpha = 1.0\n",
    "    # We will compute and store the training error after each iteration\n",
    "    errorTrain = np.zeros(numIters)\n",
    "    for i in range(numIters):\n",
    "        # Use getLabeledPrediction from (3b) with trainData to obtain an RDD of (label, prediction)\n",
    "        # tuples.  Note that the weights all equal 0 for the first iteration, so the predictions will\n",
    "        # have large errors to start.\n",
    "        labelsAndPredsTrain = trainData.map(lambda a: getLabeledPrediction(w, a))\n",
    "        errorTrain[i] = calcRMSE(labelsAndPredsTrain)\n",
    "\n",
    "        # Calculate the `gradient`.  Make use of the `gradientSummand` function you wrote in (3a).\n",
    "        # Note that `gradient` sould be a `DenseVector` of length `d`.\n",
    "        gradient = trainData.map(lambda lp: gradientSummand(w, lp)).sum()\n",
    "\n",
    "        # Update the weights\n",
    "        alpha_i = alpha / (n * np.sqrt(i+1))\n",
    "        w -= alpha_i*gradient\n",
    "    return w, errorTrain\n",
    "\n",
    "# create a toy dataset with n = 10, d = 3, and then run 5 iterations of gradient descent\n",
    "# note: the resulting model will not be useful; the goal here is to verify that\n",
    "# linregGradientDescent is working properly\n",
    "exampleN = 10\n",
    "exampleD = 3\n",
    "exampleData = (sc\n",
    "               .parallelize(parsedTrainData.take(exampleN))\n",
    "               .map(lambda lp: LabeledPoint(lp.label, lp.features[0:exampleD])))\n",
    "print exampleData.take(2)\n",
    "exampleNumIters = 5\n",
    "exampleWeights, exampleErrorTrain = linregGradientDescent(exampleData, exampleNumIters)\n",
    "print exampleWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "expectedOutput = [48.88110449,  36.01144093, 30.25350092]\n",
    "Test.assertTrue(np.allclose(exampleWeights, expectedOutput), 'value of exampleWeights is incorrect')\n",
    "expectedError = [79.72013547, 30.27835699,  9.27842641,  9.20967856,  9.19446483]\n",
    "Test.assertTrue(np.allclose(exampleErrorTrain, expectedError),\n",
    "                'value of exampleErrorTrain is incorrect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE:\n",
      "\tBaseline = 21.586\n",
      "\tLR0 = 19.192\n"
     ]
    }
   ],
   "source": [
    "numIters = 50\n",
    "weightsLR0, errorTrainLR0 = linregGradientDescent(parsedTrainData, numIters)\n",
    "\n",
    "labelsAndPreds = parsedValData.map(lambda lp: getLabeledPrediction(weightsLR0, lp))\n",
    "rmseValLR0 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(rmseValBase,\n",
    "                                                                       rmseValLR0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "expectedOutput = [22.64535883, 20.064699, -0.05341901, 8.2931319, 5.79155768, -4.51008084,\n",
    "                  15.23075467, 3.8465554, 9.91992022, 5.97465933, 11.36849033, 3.86452361]\n",
    "Test.assertTrue(np.allclose(weightsLR0, expectedOutput), 'incorrect value for weightsLR0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIters = 500  # iterations\n",
    "alpha = 1.0  # step\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.682292427,14.7439059559,-0.0935105608897,6.22080088829,4.01454261926,-3.30214858535,11.0403027232,2.67190962854,7.18925791279,4.46093254586,8.14950409475,2.75135810882] 13.3335907631\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "firstModel = LinearRegressionWithSGD.train(parsedTrainData, \n",
    "                                           iterations=numIters, \n",
    "                                           step=alpha, \n",
    "                                           miniBatchFraction=miniBatchFrac, \n",
    "                                           initialWeights=None, \n",
    "                                           regParam=reg, \n",
    "                                           regType=regType, \n",
    "                                           intercept=useIntercept \n",
    "                                           )\n",
    "\n",
    "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
    "weightsLR1 = firstModel.weights\n",
    "interceptLR1 = firstModel.intercept\n",
    "print weightsLR1, interceptLR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "expectedIntercept = 13.3335907631\n",
    "expectedWeights = [16.682292427, 14.7439059559, -0.0935105608897, 6.22080088829, 4.01454261926, -3.30214858535,\n",
    "                   11.0403027232, 2.67190962854, 7.18925791279, 4.46093254586, 8.14950409475, 2.75135810882]\n",
    "Test.assertTrue(np.allclose(interceptLR1, expectedIntercept), 'incorrect value for interceptLR1')\n",
    "Test.assertTrue(np.allclose(weightsLR1, expectedWeights), 'incorrect value for weightsLR1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.8013380112\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "samplePoint = parsedTrainData.take(1)[0]\n",
    "samplePrediction = firstModel.predict(samplePoint.features)\n",
    "print samplePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(samplePrediction, 56.8013380112),\n",
    "                'incorrect value for samplePrediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE:\n",
      "\tBaseline = 21.586\n",
      "\tLR0 = 19.192\n",
      "\tLR1 = 19.691\n"
     ]
    }
   ],
   "source": [
    "labelsAndPreds = parsedValData.map(lambda lp:(lp.label,firstModel.predict(lp.features)))\n",
    "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}' +\n",
    "       '\\n\\tLR1 = {2:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(rmseValLR1, 19.691247), 'incorrect value for rmseValLR1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0171700716\n",
      "17.0175981807\n",
      "23.8007746698\n",
      "Validation RMSE:\n",
      "\tBaseline = 21.586\n",
      "\tLR0 = 19.192\n",
      "\tLR1 = 19.691\n",
      "\tLRGrid = 17.017\n"
     ]
    }
   ],
   "source": [
    "bestRMSE = rmseValLR1\n",
    "bestRegParam = reg\n",
    "bestModel = firstModel\n",
    "\n",
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "for reg in [1e-10, 1e-5, 1.0]:\n",
    "    model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                          miniBatchFrac, regParam=reg,\n",
    "                                          regType='l2', intercept=True)\n",
    "    labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
    "    rmseValGrid = calcRMSE(labelsAndPreds)\n",
    "    print rmseValGrid\n",
    "\n",
    "    if rmseValGrid < bestRMSE:\n",
    "        bestRMSE = rmseValGrid\n",
    "        bestRegParam = reg\n",
    "        bestModel = model\n",
    "rmseValLRGrid = bestRMSE\n",
    "\n",
    "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n' +\n",
    "       '\\tLRGrid = {3:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1, rmseValLRGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(17.017170, rmseValLRGrid), 'incorrect value for rmseValLRGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1e-05, numIters = 500, RMSE = 56.893\n",
      "alpha = 1e-05, numIters = 5, RMSE = 56.970\n",
      "alpha = 1e+01, numIters = 500, RMSE = 33110728225679002898243535475370381153231748093308519592022542725707151441177139778832831219138213677907418329889500037120.000\n",
      "alpha = 1e+01, numIters = 5, RMSE = 355124752.221\n"
     ]
    }
   ],
   "source": [
    "reg = bestRegParam\n",
    "modelRMSEs = []\n",
    "\n",
    "for alpha in [1e-5, 10]:\n",
    "    for numIters in [500, 5]:\n",
    "        model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
    "                                              miniBatchFrac, regParam=reg,\n",
    "                                              regType='l2', intercept=True)\n",
    "        labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
    "        rmseVal = calcRMSE(labelsAndPreds)\n",
    "        print 'alpha = {0:.0e}, numIters = {1}, RMSE = {2:.3f}'.format(alpha, numIters, rmseVal)\n",
    "        modelRMSEs.append(rmseVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0,[2.0,3.0,4.0,6.0,6.0,9.0])\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def twoWayInteractions(lp):\n",
    "    \"\"\"Creates a new `LabeledPoint` that includes two-way interactions.\n",
    "\n",
    "    Note:\n",
    "        For features [x, y] the two-way interactions would be [x^2, x*y, y*x, y^2] and these\n",
    "        would be appended to the original [x, y] feature list.\n",
    "\n",
    "    Args:\n",
    "        lp (LabeledPoint): The label and features for this observation.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The new `LabeledPoint` should have the same label as `lp`.  Its features\n",
    "            should include the features from `lp` followed by the two-way interaction features.\n",
    "    \"\"\"\n",
    "    two_way = [float(k[0]*k[1]) for k in itertools.product(lp.features,lp.features)]\n",
    "    return LabeledPoint(lp.label,np.hstack((lp.features, two_way))\n",
    ")\n",
    "print twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
    "trainDataInteract = parsedTrainData.map(twoWayInteractions)\n",
    "valDataInteract = parsedValData.map(twoWayInteractions)\n",
    "testDataInteract = parsedTestData.map(twoWayInteractions)\n",
    "\n",
    "# Transform the existing train, validation, and test sets to include two-way interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "twoWayExample = twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
    "Test.assertTrue(np.allclose(sorted(twoWayExample.features),\n",
    "                            sorted([2.0, 3.0, 4.0, 6.0, 6.0, 9.0])),\n",
    "                'incorrect features generatedBy twoWayInteractions')\n",
    "twoWayPoint = twoWayInteractions(LabeledPoint(1.0, [1, 2, 3]))\n",
    "Test.assertTrue(np.allclose(sorted(twoWayPoint.features),\n",
    "                            sorted([1.0,2.0,3.0,1.0,2.0,3.0,2.0,4.0,6.0,3.0,6.0,9.0])),\n",
    "                'incorrect features generated by twoWayInteractions')\n",
    "Test.assertEquals(twoWayPoint.label, 1.0, 'incorrect label generated by twoWayInteractions')\n",
    "Test.assertTrue(np.allclose(sum(trainDataInteract.take(1)[0].features), 40.821870576035529),\n",
    "                'incorrect features in trainDataInteract')\n",
    "Test.assertTrue(np.allclose(sum(valDataInteract.take(1)[0].features), 45.457719932695696),\n",
    "                'incorrect features in valDataInteract')\n",
    "Test.assertTrue(np.allclose(sum(testDataInteract.take(1)[0].features), 35.109111632783168),\n",
    "                'incorrect features in testDataInteract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE:\n",
      "\tBaseline = 21.586\n",
      "\tLR0 = 19.192\n",
      "\tLR1 = 19.691\n",
      "\tLRGrid = 17.017\n",
      "\tLRInteract = 15.689\n"
     ]
    }
   ],
   "source": [
    "numIters = 500\n",
    "alpha = 1.0\n",
    "miniBatchFrac = 1.0\n",
    "reg = 1e-10\n",
    "\n",
    "modelInteract = LinearRegressionWithSGD.train(trainDataInteract, numIters, alpha,\n",
    "                                              miniBatchFrac, regParam=reg,\n",
    "                                              regType='l2', intercept=True)\n",
    "labelsAndPredsInteract = valDataInteract.map(lambda lp: (lp.label, modelInteract.predict(lp.features)))\n",
    "rmseValInteract = calcRMSE(labelsAndPredsInteract)\n",
    "\n",
    "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n\\tLRGrid = ' +\n",
    "       '{3:.3f}\\n\\tLRInteract = {4:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1,\n",
    "                                                 rmseValLRGrid, rmseValInteract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(np.allclose(rmseValInteract, 15.6894664683), 'incorrect value for rmseValInteract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:\n",
      "\tBaseline = 22.137\n",
      "\tLRInteract = 16.327\n"
     ]
    }
   ],
   "source": [
    "labelsAndPredsTest = testDataInteract.map(lambda lp: (lp.label, modelInteract.predict(lp.features)))\n",
    "rmseTestInteract = calcRMSE(labelsAndPredsTest)\n",
    "print ('Test RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLRInteract = {1:.3f}'\n",
    "       .format(rmseTestBase, rmseTestInteract))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
