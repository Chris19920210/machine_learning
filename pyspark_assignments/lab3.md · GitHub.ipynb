<!DOCTYPE html>
<html class=" is-copy-enabled" lang="en"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# object: http://ogp.me/ns/object# article: http://ogp.me/ns/article# profile: http://ogp.me/ns/profile#">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">

    <link crossorigin="anonymous" href="lab3.md%20%C2%B7%20GitHub_files/github-8a53a53d5feade5191874a5bbafa52ba0d8f6eeb48011f6b31178.css" integrity="sha256-ilOlPV/q3lGRh0pbuvpSug2PbutIAR9rMReI/bdHuAQ=" media="all" rel="stylesheet">
    <link crossorigin="anonymous" href="lab3.md%20%C2%B7%20GitHub_files/github2-887112fc6a8f9beb22d42880e4d4050fca76b0ce5ad761379e9b.css" integrity="sha256-iHES/GqPm+si1CiA5NQFD8p2sM5a12E3npuQdJsoSt0=" media="all" rel="stylesheet">
    
    
    

    <link as="script" href="lab3.md%20%C2%B7%20GitHub_files/frameworks-ee521b8e9facac68ff27e93fc3ae0f8ed811d7bf9e434e84f4.js" rel="preload">
    <link as="script" href="lab3.md%20%C2%B7%20GitHub_files/github-29cffaf54a9e723218fcaeaf352c7c455884eb1843422e42e2284a.js" rel="preload">

    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Language" content="en">
    <meta name="viewport" content="width=1020">
    <meta content="origin-when-cross-origin" name="referrer">
    
    <title>lab3.md Â· GitHub</title>
    <link rel="search" type="application/opensearchdescription+xml" href="https://gist.github.com/opensearch.xml" title="GitHub">
    <link rel="fluid-icon" href="https://gist.github.com/fluidicon.png" title="GitHub">
    <link rel="apple-touch-icon" href="https://gist.github.com/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="57x57" href="https://gist.github.com/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="https://gist.github.com/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="https://gist.github.com/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="https://gist.github.com/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="https://gist.github.com/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="https://gist.github.com/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="https://gist.github.com/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="https://gist.github.com/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="https://gist.github.com/apple-touch-icon-180x180.png">
    <meta property="fb:app_id" content="1401488693436528">

      <meta content="https://avatars2.githubusercontent.com/u/2705719?v=3&amp;s=400" name="twitter:image:src"><meta content="@github" name="twitter:site"><meta content="summary" name="twitter:card"><meta content="lab3.md" name="twitter:title"><meta content="" name="twitter:description">
      <meta content="https://avatars2.githubusercontent.com/u/2705719?v=3&amp;s=400" property="og:image"><meta content="Gist" property="og:site_name"><meta content="object" property="og:type"><meta content="lab3.md" property="og:title"><meta content="https://gist.github.com/marianboda/469651cbcda0d92f02ee" property="og:url"><meta content="" property="og:description">
      <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">
    <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">
    <link rel="assets" href="https://assets-cdn.github.com/">
    
    <meta name="pjax-timeout" content="1000">
    

    <meta name="msapplication-TileImage" content="/windows-tile.png">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="selected-link" value="gist_code" data-pjax-transient="">

    <meta name="google-site-verification" content="KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU">
<meta name="google-site-verification" content="ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA">
    <meta name="google-analytics" content="UA-3769691-4">

<meta content="collector.githubapp.com" name="octolytics-host"><meta content="gist" name="octolytics-app-id"><meta content="32C84B50:3F68:2EBA7C2:56BBC101" name="octolytics-dimension-request_id">
<meta content="/&lt;user-name&gt;/&lt;gist-id&gt;" data-pjax-transient="true" name="analytics-location">



  <meta class="js-ga-set" name="dimension1" content="Logged Out">


    <meta content="true" name="octolytics-dimension-public"><meta content="23672941" name="octolytics-dimension-gist_id"><meta content="469651cbcda0d92f02ee" name="octolytics-dimension-gist_name"><meta content="false" name="octolytics-dimension-anonymous"><meta content="2705719" name="octolytics-dimension-owner_id"><meta content="marianboda" name="octolytics-dimension-owner_login"><meta content="false" name="octolytics-dimension-forked">

  <meta class="js-ga-set" name="dimension5" content="public">
  <meta class="js-ga-set" name="dimension6" content="owned">
  <meta class="js-ga-set" name="dimension7" content="markdown">



        <meta name="hostname" content="gist.github.com">
    <meta name="user-login" content="">

        <meta name="expected-hostname" content="gist.github.com">
      <meta name="js-proxy-site-detection-payload" content="Mzk0YWMzMWMwN2NiYTAwZmI2OGY5ZDY1NDBiMGE2YjEzOTVmMTRlOTUyZGRmOTU1Nzk1NzVhNDA5ZmIzNTYzZXx7InJlbW90ZV9hZGRyZXNzIjoiNTAuMjAwLjc1LjgwIiwicmVxdWVzdF9pZCI6IjMyQzg0QjUwOjNGNjg6MkVCQTdDMjo1NkJCQzEwMSJ9">

      <link rel="mask-icon" href="https://assets-cdn.github.com/pinned-octocat.svg" color="#4078c0">
      <link rel="icon" type="image/x-icon" href="https://assets-cdn.github.com/favicon.ico">

    <meta content="ee585d718526bb188a9624b5711cc1a5383f4e3b" name="form-nonce">

    <meta http-equiv="x-pjax-version" content="d728699c019e98d376cf202d0c7054e7">

        <link href="https://gist.github.com/marianboda.atom" rel="alternate" title="atom" type="application/atom+xml">
  
  <link crossorigin="anonymous" href="lab3.md%20%C2%B7%20GitHub_files/gist-1b3ee13fd585252bf83f744f77dde3d58ed3c3f60b9384051c65c09.css" integrity="sha256-Gz7hP9WFJSv4P3RPd93j1Y7Tw/YLk4QFHGXAlstQW0s=" media="all" rel="stylesheet">


  </head>


  <body class="logged_out   env-production linux">
    <a href="#start-of-content" tabindex="1" class="accessibility-aid js-skip-to-content">Skip to content</a>

    
    
    



        <div class="header gist-header header-logged-out" role="banner">
  <div class="container clearfix">

    <a href="https://gist.github.com/" aria-label="Gist Homepage" class="header-logo-wordmark" data-hotkey="g d">
      <svg aria-hidden="true" class="octicon octicon-logo-github" height="28" role="img" version="1.1" viewBox="0 0 45 16" width="78"><path d="M8.64 5.19H4.88c-0.11 0-0.19 0.08-0.19 0.17v1.84c0 0.09 0.08 0.17 0.19 0.17h1.47v2.3s-0.33 0.11-1.25 0.11c-1.08 0-2.58-0.39-2.58-3.7s1.58-3.73 3.05-3.73c1.27 0 1.81 0.22 2.17 0.33 0.11 0.03 0.2-0.08 0.2-0.17l0.42-1.78c0-0.05-0.02-0.09-0.06-0.14-0.14-0.09-1.02-0.58-3.2-0.58C2.58 0 0 1.06 0 6.2s2.95 5.92 5.44 5.92c2.06 0 3.31-0.89 3.31-0.89 0.05-0.02 0.06-0.09 0.06-0.13V5.36c0-0.09-0.08-0.17-0.19-0.17h0.02zM27.7 0.44h-2.13c-0.09 0-0.17 0.08-0.17 0.17v4.09h-3.31V0.61c0-0.09-0.08-0.17-0.17-0.17h-2.13c-0.09 0-0.17 0.08-0.17 0.17v11.11c0 0.09 0.09 0.17 0.17 0.17h2.13c0.09 0 0.17-0.08 0.17-0.17V6.97h3.31l-0.02 4.75c0 0.09 0.08 0.17 0.17 0.17h2.13c0.09 0 0.17-0.08 0.17-0.17V0.61c0-0.09-0.08-0.17-0.17-0.17h0.02zM11.19 0.69c-0.77 0-1.38 0.61-1.38 1.38s0.61 1.38 1.38 1.38c0.75 0 1.36-0.61 1.36-1.38s-0.61-1.38-1.36-1.38z m1.22 3.55c0-0.09-0.08-0.17-0.17-0.17H10.11c-0.09 0-0.17 0.09-0.17 0.2 0 0 0 6.17 0 7.34 0 0.2 0.13 0.27 0.3 0.27 0 0 0.91 0 1.92 0 0.2 0 0.25-0.09 0.25-0.27 0-0.39 0-7.36 0-7.36v-0.02z m23.52-0.16h-2.09c-0.11 0-0.17 0.08-0.17 0.19v5.44s-0.55 0.39-1.3 0.39-0.97-0.34-0.97-1.09c0-0.73 0-4.75 0-4.75 0-0.09-0.08-0.17-0.17-0.17h-2.14c-0.09 0-0.17 0.08-0.17 0.17 0 0 0 2.91 0 5.11s1.23 2.75 2.92 2.75c1.39 0 2.52-0.77 2.52-0.77s0.05 0.39 0.08 0.45c0.02 0.05 0.09 0.09 0.16 0.09h1.34c0.11 0 0.17-0.08 0.17-0.17l0.02-7.47c0-0.09-0.08-0.17-0.19-0.17z m5.77-0.25c-1.2 0-2.02 0.53-2.02 0.53V0.59c0-0.09-0.08-0.17-0.17-0.17h-2.13c-0.09 0-0.17 0.08-0.17 0.17l-0.02 11.11c0 0.09 0.09 0.17 0.19 0.17h1.48c0.06 0 0.11-0.02 0.14-0.08 0.05-0.06 0.09-0.52 0.09-0.52s0.88 0.83 2.52 0.83c1.94 0 3.05-0.98 3.05-4.41s-1.77-3.88-2.97-3.88z m-0.83 6.27c-0.73-0.02-1.22-0.36-1.22-0.36V6.22s0.48-0.3 1.08-0.34c0.77-0.08 1.5 0.16 1.5 1.97 0 1.91-0.33 2.28-1.36 2.25z m-22.33-0.05c-0.09 0-0.33 0.05-0.58 0.05-0.78 0-1.05-0.36-1.05-0.83s0-3.13 0-3.13h1.59c0.09 0 0.16-0.08 0.16-0.19V4.25c0-0.09-0.08-0.17-0.16-0.17h-1.59V1.97c0-0.08-0.05-0.13-0.14-0.13H14.61c-0.09 0-0.14 0.05-0.14 0.13v2.17s-1.09 0.27-1.16 0.28c-0.08 0.02-0.13 0.09-0.13 0.17v1.36c0 0.11 0.08 0.19 0.17 0.19h1.11s0 1.44 0 3.28c0 2.44 1.7 2.69 2.86 2.69 0.53 0 1.17-0.17 1.27-0.22 0.06-0.02 0.09-0.09 0.09-0.16v-1.5c0-0.11-0.08-0.19-0.17-0.19h0.02z"></path></svg>
      <svg aria-hidden="true" class="octicon octicon-logo-gist" height="28" role="img" version="1.1" viewBox="0 0 24 16" width="40"><path d="M4.7 6.72h2.45v4.02c-0.55 0.27-1.64 0.34-2.53 0.34-2.56 0-3.48-2.2-3.48-5.05 0-2.83 0.92-5.05 3.48-5.05 1.27 0 2.06 0.23 3.28 0.73v-1.06c-0.64-0.33-1.66-0.66-3.28-0.66-3.5 0-4.63 2.69-4.63 6.03s1.11 6.03 4.63 6.03c1.64 0 2.8-0.27 3.59-0.64v-5.69h-3.52v0.98z m6.39 3.73v-6.39h-1.06v6.27c0 1.25 0.59 1.72 1.72 1.72v-0.89c-0.48 0-0.66-0.16-0.66-0.7z m0.25-8.73c0-0.44-0.34-0.78-0.78-0.78s-0.78 0.34-0.78 0.78 0.34 0.78 0.78 0.78 0.78-0.34 0.78-0.78z m4.33 5.69c-1.5-0.13-1.78-0.48-1.78-1.17 0-0.77 0.33-1.34 1.88-1.34 1.05 0 1.66 0.16 2.27 0.36v-0.94c-0.69-0.3-1.52-0.39-2.25-0.39-2.2 0-2.92 1.2-2.92 2.31 0 1.08 0.47 1.88 2.73 2.08 1.55 0.13 1.77 0.63 1.77 1.34 0 0.73-0.44 1.42-2.06 1.42-1.11 0-1.86-0.19-2.34-0.36v0.94c0.5 0.2 1.58 0.39 2.33 0.39 2.38 0 3.14-1.2 3.14-2.41 0-1.28-0.53-2.03-2.75-2.23z m8.59-2.47v-0.86h-2.42v-2.5l-1.09 0.31v2.11l-1.56 0.45v0.48h1.56v5c0 1.53 1.2 2.13 2.5 2.13 0.2 0 0.52-0.02 0.7-0.06v-0.88c-0.2 0.02-0.41 0.03-0.61 0.03-0.98 0-1.5-0.39-1.5-1.34v-4.88h2.42z"></path></svg>
</a>
    <div class="site-search js-site-search" role="search">
        <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/search" method="get"><div style="margin:0;padding:0;display:inline"><input name="utf8" value="â" type="hidden"></div>
  <label class="js-chromeless-input-container form-control">
    <input class="js-site-search-focus chromeless-input" data-hotkey="s" name="q" placeholder="Searchâ¦" tabindex="1" autocorrect="off" autocomplete="off" autocapitalize="off" type="text">
  </label>

</form>
    </div>
    <ul class="header-nav left" role="navigation">
      <li class="header-nav-item">
        <a href="https://gist.github.com/discover" class="header-nav-link" data-ga-click="Header, go to all gists, text:all gists">All gists</a>
      </li>

      <li class="header-nav-item">
        <a href="https://github.com/" class="header-nav-link" data-ga-click="Header, go to GitHub, text:GitHub">GitHub</a>
      </li>
    </ul>

      <div class="header-actions" role="navigation">
        <a href="https://gist.github.com/join?source=header-gist" class="btn btn-primary" data-ga-click="Header, sign up">Sign up for a GitHub account</a>
        <a href="https://gist.github.com/auth/github?return_to=gist" class="btn" data-ga-click="Header, sign in">Sign in</a>
      </div>

  </div>
</div>




    <div id="start-of-content" class="accessibility-aid"></div>

      <div id="js-flash-container">
</div>


    <div role="main" class="main-content">
      
  <div itemscope="" itemtype="http://schema.org/WebPage">
    <div id="gist-pjax-container" class="gist-content-wrapper context-loader-container js-repo-nav-next" data-pjax-container="">
          <div class="gist-detail-intro gist-banner">
      <div class="container">
        <a href="https://gist.github.com/" class="btn btn-outline right">Create a gist now</a>
        <p class="lead">
          Instantly share code, notes, and snippets.
        </p>
      </div>
    </div>


  <div class="gisthead pagehead repohead instapaper_ignore readability-menu experiment-repo-nav">
    <div class="container">
        

<div class="container repohead-details-container">

  <ul class="pagehead-actions">


    <li>
        <a href="https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Fmarianboda%2F469651cbcda0d92f02ee" aria-label="You must be signed in to star a gist" class="btn btn-sm btn-with-count tooltipped tooltipped-n" rel="nofollow">
    <svg aria-hidden="true" class="octicon octicon-star" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M14 6l-4.9-0.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14l4.33-2.33 4.33 2.33L10.4 9.26 14 6z"></path></svg>
    Star
</a>
  <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee/stargazers" class="social-count">
    0
</a>
    </li>

      <li>
          <a href="https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Fmarianboda%2F469651cbcda0d92f02ee" aria-label="You must be signed in to fork a gist" class="btn btn-sm btn-with-count tooltipped tooltipped-n" rel="nofollow">
    <svg aria-hidden="true" class="octicon octicon-repo-forked" height="16" role="img" version="1.1" viewBox="0 0 10 16" width="10"><path d="M8 1c-1.11 0-2 0.89-2 2 0 0.73 0.41 1.38 1 1.72v1.28L5 8 3 6v-1.28c0.59-0.34 1-0.98 1-1.72 0-1.11-0.89-2-2-2S0 1.89 0 3c0 0.73 0.41 1.38 1 1.72v1.78l3 3v1.78c-0.59 0.34-1 0.98-1 1.72 0 1.11 0.89 2 2 2s2-0.89 2-2c0-0.73-0.41-1.38-1-1.72V9.5l3-3V4.72c0.59-0.34 1-0.98 1-1.72 0-1.11-0.89-2-2-2zM2 4.2c-0.66 0-1.2-0.55-1.2-1.2s0.55-1.2 1.2-1.2 1.2 0.55 1.2 1.2-0.55 1.2-1.2 1.2z m3 10c-0.66 0-1.2-0.55-1.2-1.2s0.55-1.2 1.2-1.2 1.2 0.55 1.2 1.2-0.55 1.2-1.2 1.2z m3-10c-0.66 0-1.2-0.55-1.2-1.2s0.55-1.2 1.2-1.2 1.2 0.55 1.2 1.2-0.55 1.2-1.2 1.2z"></path></svg>
    Fork
</a>
  <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee/forks" class="social-count">
    5
</a>
      </li>

  </ul>

  <h1 itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb" class="entry-title public css-truncate">
    <img alt="@marianboda" class="avatar gist-avatar" src="lab3.md%20%C2%B7%20GitHub_files/2705719.png" width="26" height="26">
    <span class="author"><a href="https://gist.github.com/marianboda" class="url fn" itemprop="url" rel="author"><span itemprop="title">marianboda</span></a></span><!--
        --><span class="path-divider">/</span><!--
        --><strong class="gist-header-title css-truncate-target"><a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee">lab3.md</a></strong>

    <span class="page-context-loader">
      <img alt="" src="lab3.md%20%C2%B7%20GitHub_files/octocat-spinner-32.gif" width="16" height="16">
    </span>

    <div class="gist-timestamp">Created <time title="Jun 24, 2015, 12:56 PM CDT" datetime="2015-06-24T17:56:39Z" is="time-ago">8 months ago</time></div>
  </h1>
</div>

<div class="container gist-file-navigation">
  <div class="right file-navigation-options" data-multiple="">

    <div class="file-navigation-option">
  <input name="protocol_type" value="clone" type="hidden">

  <div class="select-menu js-menu-container js-select-menu">
    <div class="input-group js-select-button js-zeroclipboard-container">
      <div class="input-group-button">
  <button type="button" class="btn btn-sm select-menu-button js-menu-target" data-ga-click="Repository, clone Embed, location:repo overview">
    Embed
  </button>
</div>
<input class="input-monospace input-mini js-zeroclipboard-target js-url-field" value="&lt;script src=&quot;https://gist.github.com/marianboda/469651cbcda0d92f02ee.js&quot;&gt;&lt;/script&gt;" readonly="readonly" type="text">
<div class="input-group-button">
  <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><svg aria-hidden="true" class="octicon octicon-clippy" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M2 12h4v1H2v-1z m5-6H2v1h5v-1z m2 3V7L6 10l3 3V11h5V9H9z m-4.5-1H2v1h2.5v-1zM2 11h2.5v-1H2v1z m9 1h1v2c-0.02 0.28-0.11 0.52-0.3 0.7s-0.42 0.28-0.7 0.3H1c-0.55 0-1-0.45-1-1V3c0-0.55 0.45-1 1-1h3C4 0.89 4.89 0 6 0s2 0.89 2 2h3c0.55 0 1 0.45 1 1v5h-1V5H1v9h10V12zM2 4h8c0-0.55-0.45-1-1-1h-1c-0.55 0-1-0.45-1-1s-0.45-1-1-1-1 0.45-1 1-0.45 1-1 1h-1c-0.55 0-1 0.45-1 1z"></path></svg></button>
</div>

    </div>

    <div class="select-menu-modal-holder">
      <div class="select-menu-modal js-menu-content" aria-hidden="true">
        <div class="select-menu-header">
          <svg aria-label="Close" class="octicon octicon-x js-menu-close" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M7.48 8l3.75 3.75-1.48 1.48-3.75-3.75-3.75 3.75-1.48-1.48 3.75-3.75L0.77 4.25l1.48-1.48 3.75 3.75 3.75-3.75 1.48 1.48-3.75 3.75z"></path></svg>
          <span class="select-menu-title">What would you like to do?</span>
        </div>

        <div class="select-menu-list js-navigation-container" role="menu">
            <div class="select-menu-item js-navigation-item selected" role="menuitem" tabindex="0">
              <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M12 5L4 13 0 9l1.5-1.5 2.5 2.5 6.5-6.5 1.5 1.5z"></path></svg>
              <div class="select-menu-item-text">
                <input name="protocol_selector" value="embed" checked="checked" type="radio">
                <span class="select-menu-item-heading">
                  
                  Embed
                </span>
                  <span class="description">
                    Embed this gist in your website.
                  </span>
                <span class="js-select-button-text hidden-select-button-text">
                  <div class="input-group-button">
  <button type="button" class="btn btn-sm select-menu-button js-menu-target" data-ga-click="Repository, clone Embed, location:repo overview">
    Embed
  </button>
</div>
<input class="input-monospace input-mini js-zeroclipboard-target js-url-field" value="&lt;script src=&quot;https://gist.github.com/marianboda/469651cbcda0d92f02ee.js&quot;&gt;&lt;/script&gt;" readonly="readonly" type="text">
<div class="input-group-button">
  <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><svg aria-hidden="true" class="octicon octicon-clippy" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M2 12h4v1H2v-1z m5-6H2v1h5v-1z m2 3V7L6 10l3 3V11h5V9H9z m-4.5-1H2v1h2.5v-1zM2 11h2.5v-1H2v1z m9 1h1v2c-0.02 0.28-0.11 0.52-0.3 0.7s-0.42 0.28-0.7 0.3H1c-0.55 0-1-0.45-1-1V3c0-0.55 0.45-1 1-1h3C4 0.89 4.89 0 6 0s2 0.89 2 2h3c0.55 0 1 0.45 1 1v5h-1V5H1v9h10V12zM2 4h8c0-0.55-0.45-1-1-1h-1c-0.55 0-1-0.45-1-1s-0.45-1-1-1-1 0.45-1 1-0.45 1-1 1h-1c-0.55 0-1 0.45-1 1z"></path></svg></button>
</div>

                </span>
              </div>
            </div>
            <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
              <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M12 5L4 13 0 9l1.5-1.5 2.5 2.5 6.5-6.5 1.5 1.5z"></path></svg>
              <div class="select-menu-item-text">
                <input name="protocol_selector" value="share" type="radio">
                <span class="select-menu-item-heading">
                  
                  Share
                </span>
                  <span class="description">
                    Copy sharable URL for this gist.
                  </span>
                <span class="js-select-button-text hidden-select-button-text">
                  <div class="input-group-button">
  <button type="button" class="btn btn-sm select-menu-button js-menu-target" data-ga-click="Repository, clone Share, location:repo overview">
    Share
  </button>
</div>
<input class="input-monospace input-mini js-zeroclipboard-target js-url-field" value="https://gist.github.com/marianboda/469651cbcda0d92f02ee" readonly="readonly" type="text">
<div class="input-group-button">
  <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><svg aria-hidden="true" class="octicon octicon-clippy" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M2 12h4v1H2v-1z m5-6H2v1h5v-1z m2 3V7L6 10l3 3V11h5V9H9z m-4.5-1H2v1h2.5v-1zM2 11h2.5v-1H2v1z m9 1h1v2c-0.02 0.28-0.11 0.52-0.3 0.7s-0.42 0.28-0.7 0.3H1c-0.55 0-1-0.45-1-1V3c0-0.55 0.45-1 1-1h3C4 0.89 4.89 0 6 0s2 0.89 2 2h3c0.55 0 1 0.45 1 1v5h-1V5H1v9h10V12zM2 4h8c0-0.55-0.45-1-1-1h-1c-0.55 0-1-0.45-1-1s-0.45-1-1-1-1 0.45-1 1-0.45 1-1 1h-1c-0.55 0-1 0.45-1 1z"></path></svg></button>
</div>

                </span>
              </div>
            </div>
            <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
              <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M12 5L4 13 0 9l1.5-1.5 2.5 2.5 6.5-6.5 1.5 1.5z"></path></svg>
              <div class="select-menu-item-text">
                <input name="protocol_selector" value="http" type="radio">
                <span class="select-menu-item-heading">
                  Clone via
                  HTTPS
                </span>
                  <span class="description">
                    Clone with Git or checkout with SVN using the repository's web address.
                  </span>
                <span class="js-select-button-text hidden-select-button-text">
                  <div class="input-group-button">
  <button type="button" class="btn btn-sm select-menu-button js-menu-target" data-ga-click="Repository, clone HTTPS, location:repo overview">
    HTTPS
  </button>
</div>
<input class="input-monospace input-mini js-zeroclipboard-target js-url-field" value="https://gist.github.com/469651cbcda0d92f02ee.git" readonly="readonly" type="text">
<div class="input-group-button">
  <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><svg aria-hidden="true" class="octicon octicon-clippy" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M2 12h4v1H2v-1z m5-6H2v1h5v-1z m2 3V7L6 10l3 3V11h5V9H9z m-4.5-1H2v1h2.5v-1zM2 11h2.5v-1H2v1z m9 1h1v2c-0.02 0.28-0.11 0.52-0.3 0.7s-0.42 0.28-0.7 0.3H1c-0.55 0-1-0.45-1-1V3c0-0.55 0.45-1 1-1h3C4 0.89 4.89 0 6 0s2 0.89 2 2h3c0.55 0 1 0.45 1 1v5h-1V5H1v9h10V12zM2 4h8c0-0.55-0.45-1-1-1h-1c-0.55 0-1-0.45-1-1s-0.45-1-1-1-1 0.45-1 1-0.45 1-1 1h-1c-0.55 0-1 0.45-1 1z"></path></svg></button>
</div>

                </span>
              </div>
            </div>
        </div>
        <div class="select-menu-list" role="menu">
          <a class="select-menu-item select-menu-action" href="https://help.github.com/articles/which-remote-url-should-i-use" target="_blank">
            <svg aria-hidden="true" class="octicon octicon-question select-menu-item-icon" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M6 10h2v2H6V10z m4-3.5c0 2.14-2 2.5-2 2.5H6c0-0.55 0.45-1 1-1h0.5c0.28 0 0.5-0.22 0.5-0.5v-1c0-0.28-0.22-0.5-0.5-0.5h-1c-0.28 0-0.5 0.22-0.5 0.5v0.5H4c0-1.5 1.5-3 3-3s3 1 3 2.5zM7 2.3c3.14 0 5.7 2.56 5.7 5.7S10.14 13.7 7 13.7 1.3 11.14 1.3 8s2.56-5.7 5.7-5.7m0-1.3C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7S10.86 1 7 1z"></path></svg>
            <div class="select-menu-item-text">
              Learn more about clone URLs
            </div>
          </a>
        </div>
      </div>
    </div>
  </div>
</div>


      <div class="file-navigation-option">
  </div>


    <div class="file-navigation-option">
      <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee/archive/72f08d7a25f379470118245caa9fd85ad2be6ae5.zip" class="btn btn-sm" rel="nofollow" data-ga-click="Gist, download zip, location:gist overview">
        Download ZIP
      </a>
    </div>
  </div>

  <div class="left">
    <nav class="reponav js-repo-nav js-sidenav-container-pjax js-octicon-loaders" role="navigation" data-pjax="#gist-pjax-container">

  <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee" aria-label="Code" aria-selected="true" class="js-selected-navigation-item selected reponav-item" data-hotkey="g c" data-pjax="true" data-selected-links="gist_code /marianboda/469651cbcda0d92f02ee">
    <svg aria-hidden="true" class="octicon octicon-code" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M9.5 3l-1.5 1.5 3.5 3.5L8 11.5l1.5 1.5 4.5-5L9.5 3zM4.5 3L0 8l4.5 5 1.5-1.5L2.5 8l3.5-3.5L4.5 3z"></path></svg>
    Code
</a>
    <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee/revisions" aria-label="Revisions" class="js-selected-navigation-item reponav-item" data-hotkey="g r" data-pjax="true" data-selected-links="gist_revisions /marianboda/469651cbcda0d92f02ee/revisions">
      <svg aria-hidden="true" class="octicon octicon-git-commit" height="16" role="img" version="1.1" viewBox="0 0 14 16" width="14"><path d="M10.86 7c-0.45-1.72-2-3-3.86-3s-3.41 1.28-3.86 3H0v2h3.14c0.45 1.72 2 3 3.86 3s3.41-1.28 3.86-3h3.14V7H10.86zM7 10.2c-1.22 0-2.2-0.98-2.2-2.2s0.98-2.2 2.2-2.2 2.2 0.98 2.2 2.2-0.98 2.2-2.2 2.2z"></path></svg>
      Revisions
      <span class="counter">1</span>
</a>

    <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee/forks" aria-label="Forks" class="js-selected-navigation-item reponav-item" data-hotkey="g f" data-pjax="true" data-selected-links="gist_forks /marianboda/469651cbcda0d92f02ee/forks">
      <svg aria-hidden="true" class="octicon octicon-git-branch" height="16" role="img" version="1.1" viewBox="0 0 10 16" width="10"><path d="M10 5c0-1.11-0.89-2-2-2s-2 0.89-2 2c0 0.73 0.41 1.38 1 1.72v0.3c-0.02 0.52-0.23 0.98-0.63 1.38s-0.86 0.61-1.38 0.63c-0.83 0.02-1.48 0.16-2 0.45V4.72c0.59-0.34 1-0.98 1-1.72 0-1.11-0.89-2-2-2S0 1.89 0 3c0 0.73 0.41 1.38 1 1.72v6.56C0.41 11.63 0 12.27 0 13c0 1.11 0.89 2 2 2s2-0.89 2-2c0-0.53-0.2-1-0.53-1.36 0.09-0.06 0.48-0.41 0.59-0.47 0.25-0.11 0.56-0.17 0.94-0.17 1.05-0.05 1.95-0.45 2.75-1.25s1.2-1.98 1.25-3.02h-0.02c0.61-0.36 1.02-1 1.02-1.73zM2 1.8c0.66 0 1.2 0.55 1.2 1.2s-0.55 1.2-1.2 1.2-1.2-0.55-1.2-1.2 0.55-1.2 1.2-1.2z m0 12.41c-0.66 0-1.2-0.55-1.2-1.2s0.55-1.2 1.2-1.2 1.2 0.55 1.2 1.2-0.55 1.2-1.2 1.2z m6-8c-0.66 0-1.2-0.55-1.2-1.2s0.55-1.2 1.2-1.2 1.2 0.55 1.2 1.2-0.55 1.2-1.2 1.2z"></path></svg>
      Forks
      <span class="counter">5</span>
</a></nav>

  </div>
</div>


    </div><!-- /.container -->
  </div><!-- /.repohead -->

<div class="container new-discussion-timeline experiment-repo-nav">
  <div class="repository-content gist-content context-loader-container">
    



<div>
  <div class="repository-meta js-details-container">
</div>


      <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-lab3-md" class="file">
      <div class="file-header">
        <div class="file-actions">

          <a href="https://gist.github.com/marianboda/469651cbcda0d92f02ee/raw/72f08d7a25f379470118245caa9fd85ad2be6ae5/lab3.md" class="btn btn-sm ">Raw</a>
        </div>
        <div class="file-info">
          <span class="icon">
            <svg aria-hidden="true" class="octicon octicon-gist" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M7.5 5l2.5 2.5-2.5 2.5-0.75-0.75 1.75-1.75-1.75-1.75 0.75-0.75z m-3 0L2 7.5l2.5 2.5 0.75-0.75-1.75-1.75 1.75-1.75-0.75-0.75zM0 13V2c0-0.55 0.45-1 1-1h10c0.55 0 1 0.45 1 1v11c0 0.55-0.45 1-1 1H1c-0.55 0-1-0.45-1-1z m1 0h10V2H1v11z"></path></svg>
          </span>
          <a class="tooltipped tooltipped-s css-truncate" aria-label="Permalink" href="#file-lab3-md">
            <strong class="user-select-contain gist-blob-name css-truncate-target">
              lab3.md
            </strong>
          </a>
        </div>
      </div>
    
  <div id="readme" class="blob instapaper_body">
    <article class="markdown-body entry-content" itemprop="mainContentOfPage"><p>version 1.0.3</p>

<h1><a id="user-content---" class="anchor" href="#--" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><a href="https://camo.githubusercontent.com/5643006250fe6dba91cfc60dbdc1f4c526b6cd20/687474703a2f2f737061726b2d6d6f6f632e6769746875622e696f2f7765622d6173736574732f696d616765732f74615f537061726b2d6c6f676f2d736d616c6c2e706e67" target="_blank"><img src="lab3.md%20%C2%B7%20GitHub_files/687474703a2f2f737061726b2d6d6f6f632e6769746875622e696f2f7765.png" alt="Spark Logo" data-canonical-src="http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png" style="max-width:100%;"></a> + <a href="https://camo.githubusercontent.com/dd1cc9c0132abcaf1ef7192427150d2a80d2f71a/687474703a2f2f737061726b2d6d6f6f632e6769746875622e696f2f7765622d6173736574732f696d616765732f707974686f6e2d6c6f676f2d6d61737465722d76332d544d2d666c617474656e65645f736d616c6c2e706e67" target="_blank"><img src="lab3.md%20%C2%B7%20GitHub_files/687474703a2f2f737061726b2d6d6f6f632e6769746875622e696f2f_002.png" alt="Python Logo" data-canonical-src="http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png" style="max-width:100%;"></a></h1>

<h1><a id="user-content-text-analysis-and-entity-resolution" class="anchor" href="#text-analysis-and-entity-resolution" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Text Analysis and Entity Resolution</strong></h1>

<h4><a id="user-content-entity-resolution-is-a-common-yet-difficult-problem-in-data-cleaning-and-integration-this-lab-will-demonstrate-how-we-can-use-apache-spark-to-apply-powerful-and-scalable-text-analysis-techniques-and-perform-entity-resolution-across-two-datasets-of-commercial-products" class="anchor" href="#entity-resolution-is-a-common-yet-difficult-problem-in-data-cleaning-and-integration-this-lab-will-demonstrate-how-we-can-use-apache-spark-to-apply-powerful-and-scalable-text-analysis-techniques-and-perform-entity-resolution-across-two-datasets-of-commercial-products" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Entity
 resolution is a common, yet difficult problem in data cleaning and 
integration. This lab will demonstrate how we can use Apache Spark to 
apply powerful and scalable text analysis techniques and perform entity 
resolution across two datasets of commercial products.</h4>

<h4><a id="user-content-entity-resolution-or-record-linkage-is-the-term-used-by-statisticians-epidemiologists-and-historians-among-others-to-describe-the-process-of-joining-records-from-one-data-source-with-another-that-describe-the-same-entity-our-terms-with-the-same-meaning-include-entity-disambiguationlinking-duplicate-detection-deduplication-record-matching-reference-reconciliation-object-identification-datainformation-integration-and-conflation" class="anchor" href="#entity-resolution-or-record-linkage-is-the-term-used-by-statisticians-epidemiologists-and-historians-among-others-to-describe-the-process-of-joining-records-from-one-data-source-with-another-that-describe-the-same-entity-our-terms-with-the-same-meaning-include-entity-disambiguationlinking-duplicate-detection-deduplication-record-matching-reference-reconciliation-object-identification-datainformation-integration-and-conflation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Entity Resolution, or "<a href="https://en.wikipedia.org/wiki/Record_linkage">Record linkage</a>"
 is the term used by statisticians, epidemiologists, and historians, 
among others, to describe the process of joining records from one data 
source with another that describe the same entity. Our terms with the 
same meaning include, "entity disambiguation/linking", duplicate 
detection", "deduplication", "record matching", "(reference) 
reconciliation", "object identification", "data/information 
integration", and "conflation".</h4>

<h4><a id="user-content-entity-resolution-er-refers-to-the-task-of-finding-records-in-a-dataset-that-refer-to-the-same-entity-across-different-data-sources-eg-data-files-books-websites-databases-er-is-necessary-when-joining-datasets-based-on-entities-that-may-or-may-not-share-a-common-identifier-eg-database-key-uri-national-identification-number-as-may-be-the-case-due-to-differences-in-record-shape-storage-location-andor-curator-style-or-preference-a-dataset-that-has-undergone-er-may-be-referred-to-as-being-cross-linked" class="anchor" href="#entity-resolution-er-refers-to-the-task-of-finding-records-in-a-dataset-that-refer-to-the-same-entity-across-different-data-sources-eg-data-files-books-websites-databases-er-is-necessary-when-joining-datasets-based-on-entities-that-may-or-may-not-share-a-common-identifier-eg-database-key-uri-national-identification-number-as-may-be-the-case-due-to-differences-in-record-shape-storage-location-andor-curator-style-or-preference-a-dataset-that-has-undergone-er-may-be-referred-to-as-being-cross-linked" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Entity
 Resolution (ER) refers to the task of finding records in a dataset that
 refer to the same entity across different data sources (e.g., data 
files, books, websites, databases). ER is necessary when joining 
datasets based on entities that may or may not share a common identifier
 (e.g., database key, URI, National identification number), as may be 
the case due to differences in record shape, storage location, and/or 
curator style or preference. A dataset that has undergone ER may be 
referred to as being cross-linked.</h4>

<h3><a id="user-content-code" class="anchor" href="#code" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Code</h3>

<h4><a id="user-content-this-assignment-can-be-completed-using-basic-python-pyspark-transformations-and-actions-and-the-plotting-library-matplotlib-other-libraries-are-not-allowed" class="anchor" href="#this-assignment-can-be-completed-using-basic-python-pyspark-transformations-and-actions-and-the-plotting-library-matplotlib-other-libraries-are-not-allowed" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>This
 assignment can be completed using basic Python, pySpark Transformations
 and actions, and the plotting library matplotlib. Other libraries are 
not allowed.</h4>

<h3><a id="user-content-files" class="anchor" href="#files" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Files</h3>

<h4><a id="user-content-data-files-for-this-assignment-are-from-the-metric-learning-project-and-can-be-found-at" class="anchor" href="#data-files-for-this-assignment-are-from-the-metric-learning-project-and-can-be-found-at" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Data files for this assignment are from the <a href="https://code.google.com/p/metric-learning/">metric-learning</a> project and can be found at:</h4>

<p><code>cs100/lab3</code></p>

<h4><a id="user-content-the-directory-contains-the-following-files" class="anchor" href="#the-directory-contains-the-following-files" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The directory contains the following files:</h4>

<ul>
<li><strong>Google.csv</strong>, the Google Products dataset</li>
<li><strong>Amazon.csv</strong>, the Amazon dataset</li>
<li><strong>Google_small.csv</strong>, 200 records sampled from the Google data</li>
<li><strong>Amazon_small.csv</strong>, 200 records sampled from the Amazon data</li>
<li><strong>Amazon_Google_perfectMapping.csv</strong>, the "gold standard" mapping</li>
<li><strong>stopwords.txt</strong>, a list of common English words
#### Besides the complete data files, there are "sample" data files for each dataset - we will use these for <strong>Part 1</strong>.
 In addition, there is a "gold standard" file that contains all of the 
true mappings between entities in the two datasets. Every row in the 
gold standard file has a pair of record IDs (one Google, one Amazon) 
that belong to two record that describe the same thing in the real 
world. We will use the gold standard to evaluate our algorithms.</li>
</ul>

<h3><a id="user-content-part-0-preliminaries" class="anchor" href="#part-0-preliminaries" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Part 0: Preliminaries</strong></h3>

<h4><a id="user-content-we-read-in-each-of-the-files-and-create-an-rdd-consisting-of-lines" class="anchor" href="#we-read-in-each-of-the-files-and-create-an-rdd-consisting-of-lines" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We read in each of the files and create an RDD consisting of lines.</h4>

<h4><a id="user-content-for-each-of-the-data-files-googlecsv-amazoncsv-and-the-samples-we-want-to-parse-the-ids-out-of-each-record-the-ids-are-the-first-column-of-the-file-they-are-urls-for-google-and-alphanumeric-strings-for-amazon-omitting-the-headers-we-load-these-data-files-into-pair-rdds-where-the-mapping-id-is-the-key-and-the-value-is-a-string-consisting-of-the-nametitle-description-and-manufacturer-from-the-record" class="anchor" href="#for-each-of-the-data-files-googlecsv-amazoncsv-and-the-samples-we-want-to-parse-the-ids-out-of-each-record-the-ids-are-the-first-column-of-the-file-they-are-urls-for-google-and-alphanumeric-strings-for-amazon-omitting-the-headers-we-load-these-data-files-into-pair-rdds-where-the-mapping-id-is-the-key-and-the-value-is-a-string-consisting-of-the-nametitle-description-and-manufacturer-from-the-record" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>For
 each of the data files ("Google.csv", "Amazon.csv", and the samples), 
we want to parse the IDs out of each record. The IDs are the first 
column of the file (they are URLs for Google, and alphanumeric strings 
for Amazon). Omitting the headers, we load these data files into pair 
RDDs where the <em>mapping ID</em> is the key, and the value is a string consisting of the name/title, description, and manufacturer from the record.</h4>

<h4><a id="user-content-the-file-format-of-an-amazon-line-is" class="anchor" href="#the-file-format-of-an-amazon-line-is" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The file format of an Amazon line is:</h4>

<p><code>"id","title","description","manufacturer","price"</code></p>

<h4><a id="user-content-the-file-format-of-a-google-line-is" class="anchor" href="#the-file-format-of-a-google-line-is" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The file format of a Google line is:</h4>

<p><code>"id","name","description","manufacturer","price"</code></p>

<pre><code>import re
DATAFILE_PATTERN = '^(.+),"(.+)",(.*),(.*),(.*)'

def removeQuotes(s):
    """ Remove quotation marks from an input string
    Args:
        s (str): input string that might have the quote "" characters
    Returns:
        str: a string without the quote characters
    """
    return ''.join(i for i in s if i!='"')


def parseDatafileLine(datafileLine):
    """ Parse a line of the data file using the specified regular expression pattern
    Args:
        datafileLine (str): input string that is a line from the data file
    Returns:
        str: a string parsed using the given regular expression and without the quote characters
    """
    match = re.search(DATAFILE_PATTERN, datafileLine)
    if match is None:
        print 'Invalid datafile line: %s' % datafileLine
        return (datafileLine, -1)
    elif match.group(1) == '"id"':
        print 'Header datafile line: %s' % datafileLine
        return (datafileLine, 0)
    else:
        product = '%s %s %s' % (match.group(2), match.group(3), match.group(4))
        return ((removeQuotes(match.group(1)), product), 1)


import sys
import os
from test_helper import Test

baseDir = os.path.join('data')
inputPath = os.path.join('cs100', 'lab3')

GOOGLE_PATH = 'Google.csv'
GOOGLE_SMALL_PATH = 'Google_small.csv'
AMAZON_PATH = 'Amazon.csv'
AMAZON_SMALL_PATH = 'Amazon_small.csv'
GOLD_STANDARD_PATH = 'Amazon_Google_perfectMapping.csv'
STOPWORDS_PATH = 'stopwords.txt'

def parseData(filename):
    """ Parse a data file
    Args:
        filename (str): input file name of the data file
    Returns:
        RDD: a RDD of parsed lines
    """
    return (sc
            .textFile(filename, 4, 0)
            .map(parseDatafileLine)
            .cache())

def loadData(path):
    """ Load a data file
    Args:
        path (str): input file name of the data file
    Returns:
        RDD: a RDD of parsed valid lines
    """
    filename = os.path.join(baseDir, inputPath, path)
    raw = parseData(filename).cache()
    failed = (raw
              .filter(lambda s: s[1] == -1)
              .map(lambda s: s[0]))
    for line in failed.take(10):
        print '%s - Invalid datafile line: %s' % (path, line)
    valid = (raw
             .filter(lambda s: s[1] == 1)
             .map(lambda s: s[0])
             .cache())
    print '%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (path,
                                                                                        raw.count(),
                                                                                        valid.count(),
                                                                                        failed.count())
    assert failed.count() == 0
    assert raw.count() == (valid.count() + 1)
    return valid

googleSmall = loadData(GOOGLE_SMALL_PATH)
google = loadData(GOOGLE_PATH)
amazonSmall = loadData(AMAZON_SMALL_PATH)
amazon = loadData(AMAZON_PATH)

Google_small.csv - Read 201 lines, successfully parsed 200 lines, failed to parse 0 lines
Google.csv - Read 3227 lines, successfully parsed 3226 lines, failed to parse 0 lines
Amazon_small.csv - Read 201 lines, successfully parsed 200 lines, failed to parse 0 lines
Amazon.csv - Read 1364 lines, successfully parsed 1363 lines, failed to parse 0 lines
</code></pre>

<h4><a id="user-content-lets-examine-the-lines-that-were-just-loaded-in-the-two-subset-small-files---one-from-google-and-one-from-amazon" class="anchor" href="#lets-examine-the-lines-that-were-just-loaded-in-the-two-subset-small-files---one-from-google-and-one-from-amazon" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Let's examine the lines that were just loaded in the two subset (small) files - one from Google and one from Amazon</h4>

<pre><code>for line in googleSmall.take(3):
    print 'google: %s: %s\n' % (line[0], line[1])

for line in amazonSmall.take(3):
    print 'amazon: %s: %s\n' % (line[0], line[1])

google: http://www.google.com/base/feeds/snippets/11448761432933644608: spanish vocabulary builder "expand your vocabulary! contains fun lessons that both teach and entertain you'll quickly find yourself mastering new terms. includes games and more!" 

google: http://www.google.com/base/feeds/snippets/8175198959985911471: topics presents: museums of world "5 cd-rom set. step behind the velvet rope to examine some of the most treasured collections of antiquities art and inventions. includes the following the louvre - virtual visit 25 rooms in full screen interactive video detailed map of the louvre ..." 

google: http://www.google.com/base/feeds/snippets/18445827127704822533: sierrahome hse hallmark card studio special edition win 98 me 2000 xp "hallmark card studio special edition (win 98 me 2000 xp)" "sierrahome"

amazon: b000jz4hqo: clickart 950 000 - premier image pack (dvd-rom)  "broderbund"

amazon: b0006zf55o: ca international - arcserve lap/desktop oem 30pk "oem arcserve backup v11.1 win 30u for laptops and desktops" "computer associates"

amazon: b00004tkvy: noah's ark activity center (jewel case ages 3-8)  "victory multimedia"
</code></pre>

<h3><a id="user-content-part-1-er-as-text-similarity---bags-of-words" class="anchor" href="#part-1-er-as-text-similarity---bags-of-words" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Part 1: ER as Text Similarity - Bags of Words</strong></h3>

<h4><a id="user-content-a-simple-approach-to-entity-resolution-is-to-treat-all-records-as-strings-and-compute-their-similarity-with-a-string-distance-function-in-this-part-we-will-build-some-components-for-performing-bag-of-words-text-analysis-and-then-use-them-to-compute-record-similarity" class="anchor" href="#a-simple-approach-to-entity-resolution-is-to-treat-all-records-as-strings-and-compute-their-similarity-with-a-string-distance-function-in-this-part-we-will-build-some-components-for-performing-bag-of-words-text-analysis-and-then-use-them-to-compute-record-similarity" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>A
 simple approach to entity resolution is to treat all records as strings
 and compute their similarity with a string distance function. In this 
part, we will build some components for performing bag-of-words 
text-analysis, and then use them to compute record similarity.</h4>

<h4><a id="user-content-bag-of-words-is-a-conceptually-simple-yet-powerful-approach-to-text-analysis" class="anchor" href="#bag-of-words-is-a-conceptually-simple-yet-powerful-approach-to-text-analysis" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag-of-words</a> is a conceptually simple yet powerful approach to text analysis.</h4>

<h4><a id="user-content-the-idea-is-to-treat-strings-aka-documents-as-unordered-collections-of-words-or-tokens-ie-as-bags-of-words" class="anchor" href="#the-idea-is-to-treat-strings-aka-documents-as-unordered-collections-of-words-or-tokens-ie-as-bags-of-words" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The idea is to treat strings, a.k.a. <strong>documents</strong>, as <em>unordered collections</em> of words, or <strong>tokens</strong>, i.e., as bags of words.</h4>

<blockquote>
<h4><a id="user-content-note-on-terminology-a-token-is-the-result-of-parsing-the-document-down-to-the-elements-we-consider-atomic-for-the-task-at-hand--tokens-can-be-things-like-words-numbers-acronyms-or-other-exotica-like-word-roots-or-fixed-length-character-strings" class="anchor" href="#note-on-terminology-a-token-is-the-result-of-parsing-the-document-down-to-the-elements-we-consider-atomic-for-the-task-at-hand--tokens-can-be-things-like-words-numbers-acronyms-or-other-exotica-like-word-roots-or-fixed-length-character-strings" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Note on terminology</strong>:
 a "token" is the result of parsing the document down to the elements we
 consider "atomic" for the task at hand.  Tokens can be things like 
words, numbers, acronyms, or other exotica like word-roots or 
fixed-length character strings.</h4>

<h4><a id="user-content-bag-of-words-techniques-all-apply-to-any-sort-of-token-so-when-we-say-bag-of-words-we-really-mean-bag-of-tokens-strictly-speaking" class="anchor" href="#bag-of-words-techniques-all-apply-to-any-sort-of-token-so-when-we-say-bag-of-words-we-really-mean-bag-of-tokens-strictly-speaking" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Bag
 of words techniques all apply to any sort of token, so when we say 
"bag-of-words" we really mean "bag-of-tokens," strictly speaking.</h4>

<h4><a id="user-content-tokens-become-the-atomic-unit-of-text-comparison-if-we-want-to-compare-two-documents-we-count-how-many-tokens-they-share-in-common-if-we-want-to-search-for-documents-with-keyword-queries-this-is-what-google-does-then-we-turn-the-keywords-into-tokens-and-find-documents-that-contain-them-the-power-of-this-approach-is-that-it-makes-string-comparisons-insensitive-to-small-differences-that-probably-do-not-affect-meaning-much-for-example-punctuation-and-word-order" class="anchor" href="#tokens-become-the-atomic-unit-of-text-comparison-if-we-want-to-compare-two-documents-we-count-how-many-tokens-they-share-in-common-if-we-want-to-search-for-documents-with-keyword-queries-this-is-what-google-does-then-we-turn-the-keywords-into-tokens-and-find-documents-that-contain-them-the-power-of-this-approach-is-that-it-makes-string-comparisons-insensitive-to-small-differences-that-probably-do-not-affect-meaning-much-for-example-punctuation-and-word-order" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Tokens
 become the atomic unit of text comparison. If we want to compare two 
documents, we count how many tokens they share in common. If we want to 
search for documents with keyword queries (this is what Google does), 
then we turn the keywords into tokens and find documents that contain 
them. The power of this approach is that it makes string comparisons 
insensitive to small differences that probably do not affect meaning 
much, for example, punctuation and word order.</h4>
</blockquote>

<h3><a id="user-content-1a-tokenize-a-string" class="anchor" href="#1a-tokenize-a-string" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>1(a) Tokenize a String</strong></h3>

<h4><a id="user-content-implement-the-function-simpletokenizestring-that-takes-a-string-and-returns-a-list-of-non-empty-tokens-in-the-string-simpletokenize-should-split-strings-using-the-provided-regular-expression-since-we-want-to-make-token-matching-case-insensitive-make-sure-all-tokens-are-turned-lower-case-give-an-interpretation-in-natural-language-of-what-the-regular-expression-split_regex-matches" class="anchor" href="#implement-the-function-simpletokenizestring-that-takes-a-string-and-returns-a-list-of-non-empty-tokens-in-the-string-simpletokenize-should-split-strings-using-the-provided-regular-expression-since-we-want-to-make-token-matching-case-insensitive-make-sure-all-tokens-are-turned-lower-case-give-an-interpretation-in-natural-language-of-what-the-regular-expression-split_regex-matches" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Implement the function <code>simpleTokenize(string)</code> that takes a string and returns a list of non-empty tokens in the string. <code>simpleTokenize</code>
 should split strings using the provided regular expression. Since we 
want to make token-matching case insensitive, make sure all tokens are 
turned lower-case. Give an interpretation, in natural language, of what 
the regular expression, <code>split_regex</code>, matches.</h4>

<h4><a id="user-content-if-you-need-help-with-regular-expressions-try-the-site-regex101-where-you-can-interactively-explore-the-results-of-applying-different-regular-expressions-to-strings-note-that-w-includes-the-_-character--you-should-use-resplit-to-perform-the-string-split-also-make-sure-you-remove-any-empty-tokens" class="anchor" href="#if-you-need-help-with-regular-expressions-try-the-site-regex101-where-you-can-interactively-explore-the-results-of-applying-different-regular-expressions-to-strings-note-that-w-includes-the-_-character--you-should-use-resplit-to-perform-the-string-split-also-make-sure-you-remove-any-empty-tokens" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>If you need help with Regular Expressions, try the site <a href="https://regex101.com/">regex101</a> where you can interactively explore the results of applying different regular expressions to strings. <em>Note that \W includes the "_" character</em>.  You should use <a href="https://docs.python.org/2/library/re.html#re.split">re.split()</a> to perform the string split. Also, make sure you remove any empty tokens.</h4>

<pre><code># TODO: Replace &lt;FILL IN&gt; with appropriate code
quickbrownfox = 'A quick brown fox jumps over the lazy dog.'
split_regex = r'\W+'

def simpleTokenize(string):
    """ A simple implementation of input string tokenization
    Args:
        string (str): input string
    Returns:
        list: a list of tokens
    """
    return filter(len, re.split(split_regex, string.lower().strip()))

print simpleTokenize(quickbrownfox) # Should give ['a', 'quick', 'brown', ... ]

['a', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']



# TEST Tokenize a String (1a)
Test.assertEquals(simpleTokenize(quickbrownfox),
                  ['a','quick','brown','fox','jumps','over','the','lazy','dog'],
                  'simpleTokenize should handle sample text')
Test.assertEquals(simpleTokenize(' '), [], 'simpleTokenize should handle empty string')
Test.assertEquals(simpleTokenize('!!!!123A/456_B/789C.123A'), ['123a','456_b','789c','123a'],
                  'simpleTokenize should handle puntuations and lowercase result')
Test.assertEquals(simpleTokenize('fox fox'), ['fox', 'fox'],
                  'simpleTokenize should not remove duplicates')

1 test passed.
1 test passed.
1 test passed.
1 test passed.
</code></pre>

<h3><a id="user-content-1b-removing-stopwords" class="anchor" href="#1b-removing-stopwords" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(1b) Removing stopwords</strong></h3>

<h4><a id="user-content-stopwords-are-common-english-words-that-do-not-contribute-much-to-the-content-or-meaning-of-a-document-eg-the-a-is-to-etc-stopwords-add-noise-to-bag-of-words-comparisons-so-they-are-usually-excluded" class="anchor" href="#stopwords-are-common-english-words-that-do-not-contribute-much-to-the-content-or-meaning-of-a-document-eg-the-a-is-to-etc-stopwords-add-noise-to-bag-of-words-comparisons-so-they-are-usually-excluded" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><em><a href="https://en.wikipedia.org/wiki/Stop_words">Stopwords</a></em>
 are common (English) words that do not contribute much to the content 
or meaning of a document (e.g., "the", "a", "is", "to", etc.). Stopwords
 add noise to bag-of-words comparisons, so they are usually excluded.</h4>

<h4><a id="user-content-using-the-included-file-stopwordstxt-implement-tokenize-an-improved-tokenizer-that-does-not-emit-stopwords" class="anchor" href="#using-the-included-file-stopwordstxt-implement-tokenize-an-improved-tokenizer-that-does-not-emit-stopwords" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Using the included file "stopwords.txt", implement <code>tokenize</code>, an improved tokenizer that does not emit stopwords.</h4>

<pre><code># TODO: Replace &lt;FILL IN&gt; with appropriate code
stopfile = os.path.join(baseDir, inputPath, STOPWORDS_PATH)
stopwords = set(sc.textFile(stopfile).collect())
print 'These are the stopwords: %s' % stopwords

def tokenize(string):
    """ An implementation of input string tokenization that excludes stopwords
    Args:
        string (str): input string
    Returns:
        list: a list of tokens without stopwords
    """
    return filter(lambda x: x not in stopwords, simpleTokenize(string))

print tokenize(quickbrownfox) # Should give ['quick', 'brown', ... ]

These are the stopwords: set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'with', u'had', u'should', u'to', u'only', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'did', u'these', u't', u'each', u'where', u'because', u'doing', u'theirs', u'some', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'below', u'does', u'above', u'between', u'she', u'be', u'we', u'after', u'here', u'hers', u'by', u'on', u'about', u'of', u'against', u's', u'or', u'own', u'into', u'yourself', u'down', u'your', u'from', u'her', u'whom', u'there', u'been', u'few', u'too', u'themselves', u'was', u'until', u'more', u'himself', u'that', u'but', u'off', u'herself', u'than', u'those', u'he', u'me', u'myself', u'this', u'up', u'will', u'while', u'can', u'were', u'my', u'and', u'then', u'is', u'in', u'am', u'it', u'an', u'as', u'itself', u'at', u'have', u'further', u'their', u'if', u'again', u'no', u'when', u'same', u'any', u'how', u'other', u'which', u'you', u'who', u'most', u'such', u'why', u'a', u'don', u'i', u'having', u'so', u'the', u'yours', u'once'])
['quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']



# TEST Removing stopwords (1b)
Test.assertEquals(tokenize("Why a the?"), [], 'tokenize should remove all stopwords')
Test.assertEquals(tokenize("Being at the_?"), ['the_'], 'tokenize should handle non-stopwords')
Test.assertEquals(tokenize(quickbrownfox), ['quick','brown','fox','jumps','lazy','dog'],
                    'tokenize should handle sample text')

1 test passed.
1 test passed.
1 test passed.
</code></pre>

<h3><a id="user-content-1c-tokenizing-the-small-datasets" class="anchor" href="#1c-tokenizing-the-small-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(1c) Tokenizing the small datasets</strong></h3>

<h4><a id="user-content-now-lets-tokenize-the-two-small-datasets-for-each-id-in-a-dataset-tokenize-the-values-and-then-count-the-total-number-of-tokens" class="anchor" href="#now-lets-tokenize-the-two-small-datasets-for-each-id-in-a-dataset-tokenize-the-values-and-then-count-the-total-number-of-tokens" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Now let's tokenize the two <em>small</em> datasets. For each ID in a dataset, <code>tokenize</code> the values, and then count the total number of tokens.</h4>

<h4><a id="user-content-how-many-tokens-total-are-there-in-the-two-datasets" class="anchor" href="#how-many-tokens-total-are-there-in-the-two-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>How many tokens, total, are there in the two datasets?</h4>

<pre><code># TODO: Replace &lt;FILL IN&gt; with appropriate code
amazonRecToToken = amazonSmall.map(lambda x: (x[0], tokenize(x[1])))
googleRecToToken = googleSmall.map(lambda x: (x[0], tokenize(x[1])))

def countTokens(vendorRDD):
    """ Count and return the number of tokens
    Args:
        vendorRDD (RDD of (recordId, tokenizedValue)): Pair tuple of record ID to tokenized output
    Returns:
        count: count of all tokens
    """
    return vendorRDD.map(lambda x: len(x[1])).reduce(lambda a,b: a+b)

totalTokens = countTokens(amazonRecToToken) + countTokens(googleRecToToken)
print 'There are %s tokens in the combined datasets' % totalTokens

There are 22520 tokens in the combined datasets



# TEST Tokenizing the small datasets (1c)
Test.assertEquals(totalTokens, 22520, 'incorrect totalTokens')

1 test passed.
</code></pre>

<h3><a id="user-content-1d-amazon-record-with-the-most-tokens" class="anchor" href="#1d-amazon-record-with-the-most-tokens" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(1d) Amazon record with the most tokens</strong></h3>

<h4><a id="user-content-which-amazon-record-has-the-biggest-number-of-tokens" class="anchor" href="#which-amazon-record-has-the-biggest-number-of-tokens" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Which Amazon record has the biggest number of tokens?</h4>

<h4><a id="user-content-in-other-words-you-want-to-sort-the-records-and-get-the-one-with-the-largest-count-of-tokens" class="anchor" href="#in-other-words-you-want-to-sort-the-records-and-get-the-one-with-the-largest-count-of-tokens" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>In other words, you want to sort the records and get the one with the largest count of tokens.</h4>

<pre><code># TODO: Replace &lt;FILL IN&gt; with appropriate code
def findBiggestRecord(vendorRDD):
    """ Find and return the record with the largest number of tokens
    Args:
        vendorRDD (RDD of (recordId, tokens)): input Pair Tuple of record ID and tokens
    Returns:
        list: a list of 1 Pair Tuple of record ID and tokens
    """
    return vendorRDD.takeOrdered(1, lambda x: -len(x[1]))

biggestRecordAmazon = findBiggestRecord(amazonRecToToken)
print 'The Amazon record with ID "%s" has the most tokens (%s)' % (biggestRecordAmazon[0][0],
                                                                   len(biggestRecordAmazon[0][1]))

The Amazon record with ID "b000o24l3q" has the most tokens (1547)



# TEST Amazon record with the most tokens (1d)
Test.assertEquals(biggestRecordAmazon[0][0], 'b000o24l3q', 'incorrect biggestRecordAmazon')
Test.assertEquals(len(biggestRecordAmazon[0][1]), 1547, 'incorrect len for biggestRecordAmazon')

1 test passed.
1 test passed.
</code></pre>

<h3><a id="user-content-part-2-er-as-text-similarity---weighted-bag-of-words-using-tf-idf" class="anchor" href="#part-2-er-as-text-similarity---weighted-bag-of-words-using-tf-idf" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Part 2: ER as Text Similarity - Weighted Bag-of-Words using TF-IDF</strong></h3>

<h4><a id="user-content-bag-of-words-comparisons-are-not-very-good-when-all-tokens-are-treated-the-same-some-tokens-are-more-important-than-others-weights-give-us-a-way-to-specify-which-tokens-to-favor-with-weights-when-we-compare-documents-instead-of-counting-common-tokens-we-sum-up-the-weights-of-common-tokens-a-good-heuristic-for-assigning-weights-is-called-term-frequencyinverse-document-frequency-or-tf-idf-for-short" class="anchor" href="#bag-of-words-comparisons-are-not-very-good-when-all-tokens-are-treated-the-same-some-tokens-are-more-important-than-others-weights-give-us-a-way-to-specify-which-tokens-to-favor-with-weights-when-we-compare-documents-instead-of-counting-common-tokens-we-sum-up-the-weights-of-common-tokens-a-good-heuristic-for-assigning-weights-is-called-term-frequencyinverse-document-frequency-or-tf-idf-for-short" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Bag-of-words
 comparisons are not very good when all tokens are treated the same: 
some tokens are more important than others. Weights give us a way to 
specify which tokens to favor. With weights, when we compare documents, 
instead of counting common tokens, we sum up the weights of common 
tokens. A good heuristic for assigning weights is called 
"Term-Frequency/Inverse-Document-Frequency," or <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> for short.</h4>

<h4><a id="user-content-tf" class="anchor" href="#tf" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>TF</strong></h4>

<h4><a id="user-content-tf-rewards-tokens-that-appear-many-times-in-the-same-document-it-is-computed-as-the-frequency-of-a-token-in-a-document-that-is-if-document-d-contains-100-tokens-and-token-t-appears-in-d-5-times-then-the-tf-weight-of-t-in-d-is-5100--120-the-intuition-for-tf-is-that-if-a-word-occurs-often-in-a-document-then-it-is-more-important-to-the-meaning-of-the-document" class="anchor" href="#tf-rewards-tokens-that-appear-many-times-in-the-same-document-it-is-computed-as-the-frequency-of-a-token-in-a-document-that-is-if-document-d-contains-100-tokens-and-token-t-appears-in-d-5-times-then-the-tf-weight-of-t-in-d-is-5100--120-the-intuition-for-tf-is-that-if-a-word-occurs-often-in-a-document-then-it-is-more-important-to-the-meaning-of-the-document" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TF
 rewards tokens that appear many times in the same document. It is 
computed as the frequency of a token in a document, that is, if document
 <em>d</em> contains 100 tokens and token <em>t</em> appears in <em>d</em> 5 times, then the TF weight of <em>t</em> in <em>d</em> is <em>5/100 = 1/20</em>. The intuition for TF is that if a word occurs often in a document, then it is more important to the meaning of the document.</h4>

<h4><a id="user-content-idf" class="anchor" href="#idf" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>IDF</strong></h4>

<h4><a id="user-content-idf-rewards-tokens-that-are-rare-overall-in-a-dataset-the-intuition-is-that-it-is-more-significant-if-two-documents-share-a-rare-word-than-a-common-one-idf-weight-for-a-token-t-in-a-set-of-documents-u-is-computed-as-follows" class="anchor" href="#idf-rewards-tokens-that-are-rare-overall-in-a-dataset-the-intuition-is-that-it-is-more-significant-if-two-documents-share-a-rare-word-than-a-common-one-idf-weight-for-a-token-t-in-a-set-of-documents-u-is-computed-as-follows" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>IDF
 rewards tokens that are rare overall in a dataset. The intuition is 
that it is more significant if two documents share a rare word than a 
common one. IDF weight for a token, <em>t</em>, in a set of documents, <em>U</em>, is computed as follows:</h4>

<ul>
<li>#### Let <em>N</em> be the total number of documents in <em>U</em></li>
<li>#### Find <em>n(t)</em>, the number of documents in <em>U</em> that contain <em>t</em></li>
<li>#### Then <em>IDF(t) = N/n(t)</em>.
#### Note that <em>n(t)/N</em> is the frequency of <em>t</em> in <em>U</em>, and <em>N/n(t)</em> is the inverse frequency.
&gt; #### <strong>Note on terminology</strong>: Sometimes token weights 
depend on the document the token belongs to, that is, the same token may
 have a different weight when it's found in different documents.  We 
call these weights <em>local</em> weights.  TF is an example of a local 
weight, because it depends on the length of the source.  On the other 
hand, some token weights only depend on the token, and are the same 
everywhere that token is found.  We call these weights <em>global</em>, and IDF is one such weight.
#### <strong>TF-IDF</strong>
#### Finally, to bring it all together, the total TF-IDF weight for a 
token in a document is the product of its TF and IDF weights.</li>
</ul>

<h3><a id="user-content-2a-implement-a-tf-function" class="anchor" href="#2a-implement-a-tf-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(2a) Implement a TF function</strong></h3>

<h4><a id="user-content-implement-tftokens-that-takes-a-list-of-tokens-and-returns-a-python-dictionary-mapping-tokens-to-tf-weights" class="anchor" href="#implement-tftokens-that-takes-a-list-of-tokens-and-returns-a-python-dictionary-mapping-tokens-to-tf-weights" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Implement <code>tf(tokens)</code> that takes a list of tokens and returns a Python <a href="https://docs.python.org/2/tutorial/datastructures.html#dictionaries">dictionary</a> mapping tokens to TF weights.</h4>

<h4><a id="user-content-the-steps-your-function-should-perform-are" class="anchor" href="#the-steps-your-function-should-perform-are" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps your function should perform are:</h4>

<ul>
<li>#### Create an empty Python dictionary</li>
<li>#### For each of the tokens in the input <code>tokens</code> list, count 1 for each occurance and add the token to the dictionary</li>
<li><h4><a id="user-content-for-each-of-the-tokens-in-the-dictionary-divide-the-tokens-count-by-the-total-number-of-tokens-in-the-input-tokens-list" class="anchor" href="#for-each-of-the-tokens-in-the-dictionary-divide-the-tokens-count-by-the-total-number-of-tokens-in-the-input-tokens-list" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>For each of the tokens in the dictionary, divide the token's count by the total number of tokens in the input <code>tokens</code> list</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code" class="anchor" href="#todo-replace--with-appropriate-code" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def tf(tokens):
    """ Compute TF
    Args:
        tokens (list of str): input list of tokens from tokenize
    Returns:
        dictionary: a dictionary of tokens to its TF values
    """
    tokenCounts = {}
    for t in tokens:
        tokenCounts[t] = tokenCounts.get(t, 0) + (1.0/len(tokens))</p>

<pre><code>return tokenCounts
</code></pre>

<p>print tf(tokenize(quickbrownfox)) # Should give { 'quick': 0.1666 ... }</p>

<p>{'brown': 0.16666666666666666, 'lazy': 0.16666666666666666, 'jumps': 
0.16666666666666666, 'fox': 0.16666666666666666, 'dog': 
0.16666666666666666, 'quick': 0.16666666666666666}</p>

<h1><a id="user-content-test-implement-a-tf-function-2a" class="anchor" href="#test-implement-a-tf-function-2a" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Implement a TF function (2a)</h1>

<p>tf_test = tf(tokenize(quickbrownfox))
Test.assertEquals(tf_test, {'brown': 0.16666666666666666, 'lazy': 0.16666666666666666,
                             'jumps': 0.16666666666666666, 'fox': 0.16666666666666666,
                             'dog': 0.16666666666666666, 'quick': 0.16666666666666666},
                    'incorrect result for tf on sample text')
tf_test2 = tf(tokenize('one_ one_ two!'))
Test.assertEquals(tf_test2, {'one_': 0.6666666666666666, 'two': 0.3333333333333333},
                    'incorrect result for tf test')</p>

<p>1 test passed.
1 test passed.</p></li>
</ul>

<h3><a id="user-content-2b-create-a-corpus" class="anchor" href="#2b-create-a-corpus" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(2b) Create a corpus</strong></h3>

<h4><a id="user-content-create-a-pair-rdd-called-corpusrdd-consisting-of-a-combination-of-the-two-small-datasets-amazonrectotoken-and-googlerectotoken-each-element-of-the-corpusrdd-should-be-a-pair-consisting-of-a-key-from-one-of-the-small-datasets-id-or-url-and-the-value-is-the-associated-value-for-that-key-from-the-small-datasets" class="anchor" href="#create-a-pair-rdd-called-corpusrdd-consisting-of-a-combination-of-the-two-small-datasets-amazonrectotoken-and-googlerectotoken-each-element-of-the-corpusrdd-should-be-a-pair-consisting-of-a-key-from-one-of-the-small-datasets-id-or-url-and-the-value-is-the-associated-value-for-that-key-from-the-small-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Create a pair RDD called <code>corpusRDD</code>, consisting of a combination of the two small datasets, <code>amazonRecToToken</code> and <code>googleRecToToken</code>. Each element of the <code>corpusRDD</code>
 should be a pair consisting of a key from one of the small datasets (ID
 or URL) and the value is the associated value for that key from the 
small datasets.</h4>

<pre><code># TODO: Replace &lt;FILL IN&gt; with appropriate code
corpusRDD = amazonSmall.union(googleSmall)


# TEST Create a corpus (2b)
Test.assertEquals(corpusRDD.count(), 400, 'incorrect corpusRDD.count()')

1 test passed.
</code></pre>

<h3><a id="user-content-2c-implement-an-idfs-function" class="anchor" href="#2c-implement-an-idfs-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(2c) Implement an IDFs function</strong></h3>

<h4><a id="user-content-implement-idfs-that-assigns-an-idf-weight-to-every-unique-token-in-an-rdd-called-corpus-the-function-should-return-an-pair-rdd-where-the-key-is-the-unique-token-and-value-is-the-idf-weight-for-the-token" class="anchor" href="#implement-idfs-that-assigns-an-idf-weight-to-every-unique-token-in-an-rdd-called-corpus-the-function-should-return-an-pair-rdd-where-the-key-is-the-unique-token-and-value-is-the-idf-weight-for-the-token" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Implement <code>idfs</code> that assigns an IDF weight to every unique token in an RDD called <code>corpus</code>. The function should return an pair RDD where the <code>key</code> is the unique token and value is the IDF weight for the token.</h4>

<h4><a id="user-content-recall-that-the-idf-weight-for-a-token-t-in-a-set-of-documents-u-is-computed-as-follows" class="anchor" href="#recall-that-the-idf-weight-for-a-token-t-in-a-set-of-documents-u-is-computed-as-follows" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Recall that the IDF weight for a token, <em>t</em>, in a set of documents, <em>U</em>, is computed as follows:</h4>

<ul>
<li>#### Let <em>N</em> be the total number of documents in <em>U</em>.</li>
<li>#### Find <em>n(t)</em>, the number of documents in <em>U</em> that contain <em>t</em>.</li>
<li>#### Then <em>IDF(t) = N/n(t)</em>.
#### The steps your function should perform are:</li>
<li>#### Calculate <em>N</em>. Think about how you can calculate <em>N</em> from the input RDD.</li>
<li>#### Create an RDD (<em>not a pair RDD</em>) containing the unique tokens from each document in the input <code>corpus</code>. For each document, you should only include a token once, <em>even if it appears multiple times in that document.</em></li>
<li><h4><a id="user-content-for-each-of-the-unique-tokens-count-how-many-times-it-appears-in-the-document-and-then-compute-the-idf-for-that-token-nnt" class="anchor" href="#for-each-of-the-unique-tokens-count-how-many-times-it-appears-in-the-document-and-then-compute-the-idf-for-that-token-nnt" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>For each of the unique tokens, count how many times it appears in the document and then compute the IDF for that token: <em>N/n(t)</em></h4>

<h4><a id="user-content-use-your-idfs-to-compute-the-idf-weights-for-all-tokens-in-corpusrdd-the-combined-small-datasets" class="anchor" href="#use-your-idfs-to-compute-the-idf-weights-for-all-tokens-in-corpusrdd-the-combined-small-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Use your <code>idfs</code> to compute the IDF weights for all tokens in <code>corpusRDD</code> (the combined small datasets).</h4>

<h4><a id="user-content-how-many-unique-tokens-are-there" class="anchor" href="#how-many-unique-tokens-are-there" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>How many unique tokens are there?</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-1" class="anchor" href="#todo-replace--with-appropriate-code-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def idfs(corpus):
    """ Compute IDF
    Args:
        corpus (RDD): input corpus
    Returns:
        RDD: a RDD of (token, IDF value)
    """
    N = corpus.count()
    uniqueTokens = corpus.flatMap(lambda x: list(set(x[1])))</p>

<pre><code>tokenCountPairTuple = uniqueTokens.map(lambda x: (x, 1))
tokenSumPairTuple = tokenCountPairTuple.reduceByKey(lambda a,b: a+b)
return (tokenSumPairTuple.map(lambda x: (x[0], float(N)/x[1])))
</code></pre>

<p>idfsSmall = idfs(amazonRecToToken.union(googleRecToToken))
uniqueTokenCount = idfsSmall.count()</p>

<p>print 'There are %s unique tokens in the small datasets.' % uniqueTokenCount</p>

<p>There are 4772 unique tokens in the small datasets.</p>

<h1><a id="user-content-test-implement-an-idfs-function-2c" class="anchor" href="#test-implement-an-idfs-function-2c" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Implement an IDFs function (2c)</h1>

<p>Test.assertEquals(uniqueTokenCount, 4772, 'incorrect uniqueTokenCount')
tokenSmallestIdf = idfsSmall.takeOrdered(1, lambda s: s[1])[0]
Test.assertEquals(tokenSmallestIdf[0], 'software', 'incorrect smallest IDF token')
Test.assertTrue(abs(tokenSmallestIdf[1] - 4.25531914894) &lt; 0.0000000001,
                'incorrect smallest IDF value %s')</p>

<p>1 test passed.
1 test passed.
1 test passed.</p></li>
</ul>

<h3><a id="user-content-2d-tokens-with-the-smallest-idf" class="anchor" href="#2d-tokens-with-the-smallest-idf" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(2d) Tokens with the smallest IDF</strong></h3>

<h4><a id="user-content-print-out-the-11-tokens-with-the-smallest-idf-in-the-combined-small-dataset" class="anchor" href="#print-out-the-11-tokens-with-the-smallest-idf-in-the-combined-small-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Print out the 11 tokens with the smallest IDF in the combined small dataset.</h4>

<pre><code>smallIDFTokens = idfsSmall.takeOrdered(11, lambda s: s[1])
print smallIDFTokens

[('software', 4.25531914893617), ('new', 6.896551724137931), ('features', 6.896551724137931), ('use', 7.017543859649122), ('complete', 7.2727272727272725), ('easy', 7.6923076923076925), ('create', 8.333333333333334), ('system', 8.333333333333334), ('cd', 8.333333333333334), ('1', 8.51063829787234), ('windows', 8.51063829787234)]
</code></pre>

<h3><a id="user-content-2e-idf-histogram" class="anchor" href="#2e-idf-histogram" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(2e) IDF Histogram</strong></h3>

<h4><a id="user-content-plot-a-histogram-of-idf-values--be-sure-to-use-appropriate-scaling-and-bucketing-for-the-data" class="anchor" href="#plot-a-histogram-of-idf-values--be-sure-to-use-appropriate-scaling-and-bucketing-for-the-data" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Plot a histogram of IDF values.  Be sure to use appropriate scaling and bucketing for the data.</h4>

<h4><a id="user-content-first-plot-the-histogram-using-matplotlib" class="anchor" href="#first-plot-the-histogram-using-matplotlib" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>First plot the histogram using <code>matplotlib</code></h4>

<pre><code>import matplotlib.pyplot as plt

small_idf_values = idfsSmall.map(lambda s: s[1]).collect()
fig = plt.figure(figsize=(8,3))
plt.hist(small_idf_values, 50, log=True)
pass
</code></pre>

<p><a href="https://gist.github.com/marianboda/output_34_0.png" target="_blank"><img src="lab3.md%20%C2%B7%20GitHub_files/output_34_0.html" alt="png" style="max-width:100%;"></a></p>

<h3><a id="user-content-2f-implement-a-tf-idf-function" class="anchor" href="#2f-implement-a-tf-idf-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(2f) Implement a TF-IDF function</strong></h3>

<h4><a id="user-content-use-your-tf-function-to-implement-a-tfidftokens-idfs-function-that-takes-a-list-of-tokens-from-a-document-and-a-python-dictionary-of-idf-weights-and-returns-a-python-dictionary-mapping-individual-tokens-to-total-tf-idf-weights" class="anchor" href="#use-your-tf-function-to-implement-a-tfidftokens-idfs-function-that-takes-a-list-of-tokens-from-a-document-and-a-python-dictionary-of-idf-weights-and-returns-a-python-dictionary-mapping-individual-tokens-to-total-tf-idf-weights" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Use your <code>tf</code> function to implement a <code>tfidf(tokens, idfs)</code>
 function that takes a list of tokens from a document and a Python 
dictionary of IDF weights and returns a Python dictionary mapping 
individual tokens to total TF-IDF weights.</h4>

<h4><a id="user-content-the-steps-your-function-should-perform-are-1" class="anchor" href="#the-steps-your-function-should-perform-are-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps your function should perform are:</h4>

<ul>
<li>#### Calculate the token frequencies (TF) for <code>tokens</code></li>
<li><h4><a id="user-content-create-a-python-dictionary-where-each-token-maps-to-the-tokens-frequency-times-the-tokens-idf-weight" class="anchor" href="#create-a-python-dictionary-where-each-token-maps-to-the-tokens-frequency-times-the-tokens-idf-weight" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Create a Python dictionary where each token maps to the token's frequency times the token's IDF weight</h4>

<h4><a id="user-content-use-your-tfidf-function-to-compute-the-weights-of-amazon-product-record-b000hkgj8k-to-do-this-we-need-to-extract-the-record-for-the-token-from-the-tokenized-small-amazon-dataset-and-we-need-to-convert-the-idfs-for-the-small-dataset-into-a-python-dictionary-we-can-do-the-first-part-by-using-a-filter-transformation-to-extract-the-matching-record-and-a-collect-action-to-return-the-value-to-the-driver-for-the-second-part-we-use-the-collectasmap-action-to-return-the-idfs-to-the-driver-as-a-python-dictionary" class="anchor" href="#use-your-tfidf-function-to-compute-the-weights-of-amazon-product-record-b000hkgj8k-to-do-this-we-need-to-extract-the-record-for-the-token-from-the-tokenized-small-amazon-dataset-and-we-need-to-convert-the-idfs-for-the-small-dataset-into-a-python-dictionary-we-can-do-the-first-part-by-using-a-filter-transformation-to-extract-the-matching-record-and-a-collect-action-to-return-the-value-to-the-driver-for-the-second-part-we-use-the-collectasmap-action-to-return-the-idfs-to-the-driver-as-a-python-dictionary" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Use your <code>tfidf</code>
 function to compute the weights of Amazon product record 'b000hkgj8k'. 
To do this, we need to extract the record for the token from the 
tokenized small Amazon dataset and we need to convert the IDFs for the 
small dataset into a Python dictionary. We can do the first part, by 
using a <code>filter()</code> transformation to extract the matching record and a <code>collect()</code> action to return the value to the driver. For the second part, we use the <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap"><code>collectAsMap()</code> action</a> to return the IDFs to the driver as a Python dictionary.</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-2" class="anchor" href="#todo-replace--with-appropriate-code-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def tfidf(tokens, idfs):
    """ Compute TF-IDF
    Args:
        tokens (list of str): input list of tokens from tokenize
        idfs (dictionary): record to IDF value
    Returns:
        dictionary: a dictionary of records to TF-IDF values
    """</p>

<pre><code>tfs = tf(tokens)
tfIdfDict = {k: v*idfs[k] for k, v in tfs.items()}
return tfIdfDict
</code></pre>

<p>recb000hkgj8k = amazonRecToToken.filter(lambda x: x[0] == 'b000hkgj8k').collect()[0][1]
idfsSmallWeights = idfsSmall.collectAsMap()
rec_b000hkgj8k_weights = tfidf(recb000hkgj8k, idfsSmallWeights)</p>

<p>print 'Amazon record "b000hkgj8k" has tokens and weights:\n%s' % rec_b000hkgj8k_weights</p>

<p>Amazon record "b000hkgj8k" has tokens and weights:
{'autocad': 33.33333333333333, 'autodesk': 8.333333333333332, 
'courseware': 66.66666666666666, 'psg': 33.33333333333333, '2007': 
3.5087719298245617, 'customizing': 16.666666666666664, 'interface': 
3.0303030303030303}</p>

<h1><a id="user-content-test-implement-a-tf-idf-function-2f" class="anchor" href="#test-implement-a-tf-idf-function-2f" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Implement a TF-IDF function (2f)</h1>

<p>Test.assertEquals(rec_b000hkgj8k_weights,
                   {'autocad': 33.33333333333333, 'autodesk': 8.333333333333332,
                    'courseware': 66.66666666666666, 'psg': 33.33333333333333,
                    '2007': 3.5087719298245617, 'customizing': 16.666666666666664,
                    'interface': 3.0303030303030303}, 'incorrect rec_b000hkgj8k_weights')</p>

<p>1 test passed.</p></li>
</ul>

<h3><a id="user-content-part-3-er-as-text-similarity---cosine-similarity" class="anchor" href="#part-3-er-as-text-similarity---cosine-similarity" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Part 3: ER as Text Similarity - Cosine Similarity</strong></h3>

<h4><a id="user-content-now-we-are-ready-to-do-text-comparisons-in-a-formal-way-the-metric-of-string-distance-we-will-use-is-called-cosine-similarity-we-will-treat-each-document-as-a-vector-in-some-high-dimensional-space-then-to-compare-two-documents-we-compute-the-cosine-of-the-angle-between-their-two-document-vectors-this-is-much-easier-than-it-sounds" class="anchor" href="#now-we-are-ready-to-do-text-comparisons-in-a-formal-way-the-metric-of-string-distance-we-will-use-is-called-cosine-similarity-we-will-treat-each-document-as-a-vector-in-some-high-dimensional-space-then-to-compare-two-documents-we-compute-the-cosine-of-the-angle-between-their-two-document-vectors-this-is-much-easier-than-it-sounds" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Now we are ready to do text comparisons in a formal way. The metric of string distance we will use is called <strong><a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a></strong>.
 We will treat each document as a vector in some high dimensional space.
 Then, to compare two documents we compute the cosine of the angle 
between their two document vectors. This is <em>much</em> easier than it sounds.</h4>

<h4><a id="user-content-the-first-question-to-answer-is-how-do-we-represent-documents-as-vectors-the-answer-is-familiar-bag-of-words-we-treat-each-unique-token-as-a-dimension-and-treat-token-weights-as-magnitudes-in-their-respective-token-dimensions-for-example-suppose-we-use-simple-counts-as-weights-and-we-want-to-interpret-the-string-hello-world--goodbye-world-as-a-vector-then-in-the-hello-and-goodbye-dimensions-the-vector-has-value-1-in-the-world-dimension-it-has-value-2-and-it-is-zero-in-all-other-dimensions" class="anchor" href="#the-first-question-to-answer-is-how-do-we-represent-documents-as-vectors-the-answer-is-familiar-bag-of-words-we-treat-each-unique-token-as-a-dimension-and-treat-token-weights-as-magnitudes-in-their-respective-token-dimensions-for-example-suppose-we-use-simple-counts-as-weights-and-we-want-to-interpret-the-string-hello-world--goodbye-world-as-a-vector-then-in-the-hello-and-goodbye-dimensions-the-vector-has-value-1-in-the-world-dimension-it-has-value-2-and-it-is-zero-in-all-other-dimensions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The
 first question to answer is how do we represent documents as vectors? 
The answer is familiar: bag-of-words! We treat each unique token as a 
dimension, and treat token weights as magnitudes in their respective 
token dimensions. For example, suppose we use simple counts as weights, 
and we want to interpret the string "Hello, world!  Goodbye, world!" as a
 vector. Then in the "hello" and "goodbye" dimensions the vector has 
value 1, in the "world" dimension it has value 2, and it is zero in all 
other dimensions.</h4>

<h4><a id="user-content-the-next-question-is-given-two-vectors-how-do-we-find-the-cosine-of-the-angle-between-them-recall-the-formula-for-the-dot-product-of-two-vectors" class="anchor" href="#the-next-question-is-given-two-vectors-how-do-we-find-the-cosine-of-the-angle-between-them-recall-the-formula-for-the-dot-product-of-two-vectors" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The
 next question is: given two vectors how do we find the cosine of the 
angle between them? Recall the formula for the dot product of two 
vectors:</h4>

<h4><a id="user-content--a-cdot-b---a---b--cos-theta-" class="anchor" href="#-a-cdot-b---a---b--cos-theta-" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>$$ a \cdot b = | a | | b | \cos \theta $$</h4>

<h4><a id="user-content-here--a-cdot-b--sum-a_i-b_i--is-the-ordinary-dot-product-of-two-vectors-and--a--sqrt-sum-a_i2---is-the-norm-of--a-" class="anchor" href="#here--a-cdot-b--sum-a_i-b_i--is-the-ordinary-dot-product-of-two-vectors-and--a--sqrt-sum-a_i2---is-the-norm-of--a-" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Here
 $ a \cdot b = \sum a_i b_i $ is the ordinary dot product of two 
vectors, and $ |a| = \sqrt{ \sum a_i^2 } $ is the norm of $ a $.</h4>

<h4><a id="user-content-we-can-rearrange-terms-and-solve-for-the-cosine-to-find-it-is-simply-the-normalized-dot-product-of-the-vectors-with-our-vector-model-the-dot-product-and-norm-computations-are-simple-functions-of-the-bag-of-words-document-representations-so-we-now-have-a-formal-way-to-compute-similarity" class="anchor" href="#we-can-rearrange-terms-and-solve-for-the-cosine-to-find-it-is-simply-the-normalized-dot-product-of-the-vectors-with-our-vector-model-the-dot-product-and-norm-computations-are-simple-functions-of-the-bag-of-words-document-representations-so-we-now-have-a-formal-way-to-compute-similarity" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We
 can rearrange terms and solve for the cosine to find it is simply the 
normalized dot product of the vectors. With our vector model, the dot 
product and norm computations are simple functions of the bag-of-words 
document representations, so we now have a formal way to compute 
similarity:</h4>

<h4><a id="user-content--similarity--cos-theta--fraca-cdot-ba-b--fracsum-a_i-b_isqrtsum-a_i2-sqrtsum-b_i2-" class="anchor" href="#-similarity--cos-theta--fraca-cdot-ba-b--fracsum-a_i-b_isqrtsum-a_i2-sqrtsum-b_i2-" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>$$ similarity = \cos \theta = \frac{a \cdot b}{|a| |b|} = \frac{\sum a_i b_i}{\sqrt{\sum a_i^2} \sqrt{\sum b_i^2}} $$</h4>

<h4><a id="user-content-setting-aside-the-algebra-the-geometric-interpretation-is-more-intuitive-the-angle-between-two-document-vectors-is-small-if-they-share-many-tokens-in-common-because-they-are-pointing-in-roughly-the-same-direction-for-that-case-the-cosine-of-the-angle-will-be-large-otherwise-if-the-angle-is-large-and-they-have-few-words-in-common-the-cosine-is-small-therefore-cosine-similarity-scales-proportionally-with-our-intuitive-sense-of-similarity" class="anchor" href="#setting-aside-the-algebra-the-geometric-interpretation-is-more-intuitive-the-angle-between-two-document-vectors-is-small-if-they-share-many-tokens-in-common-because-they-are-pointing-in-roughly-the-same-direction-for-that-case-the-cosine-of-the-angle-will-be-large-otherwise-if-the-angle-is-large-and-they-have-few-words-in-common-the-cosine-is-small-therefore-cosine-similarity-scales-proportionally-with-our-intuitive-sense-of-similarity" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Setting
 aside the algebra, the geometric interpretation is more intuitive. The 
angle between two document vectors is small if they share many tokens in
 common, because they are pointing in roughly the same direction. For 
that case, the cosine of the angle will be large. Otherwise, if the 
angle is large (and they have few words in common), the cosine is small.
 Therefore, cosine similarity scales proportionally with our intuitive 
sense of similarity.</h4>

<h3><a id="user-content-3a-implement-the-components-of-a-cosinesimilarity-function" class="anchor" href="#3a-implement-the-components-of-a-cosinesimilarity-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(3a) Implement the components of a <code>cosineSimilarity</code> function</strong></h3>

<h4><a id="user-content-implement-the-components-of-a-cosinesimilarity-function" class="anchor" href="#implement-the-components-of-a-cosinesimilarity-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Implement the components of a <code>cosineSimilarity</code> function.</h4>

<h4><a id="user-content-use-the-tokenize-and-tfidf-functions-and-the-idf-weights-from-part-2-for-extracting-tokens-and-assigning-them-weights" class="anchor" href="#use-the-tokenize-and-tfidf-functions-and-the-idf-weights-from-part-2-for-extracting-tokens-and-assigning-them-weights" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Use the <code>tokenize</code> and <code>tfidf</code> functions, and the IDF weights from Part 2 for extracting tokens and assigning them weights.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are" class="anchor" href="#the-steps-you-should-perform-are" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Define a function <code>dotprod</code> that takes two Python 
dictionaries and produces the dot product of them, where the dot product
 is defined as the sum of the product of values for tokens that appear 
in <em>both</em> dictionaries</li>
<li>#### Define a function <code>norm</code> that returns the square root of the dot product of a dictionary and itself</li>
<li><h4><a id="user-content-define-a-function-cossim-that-returns-the-dot-product-of-two-dictionaries-divided-by-the-norm-of-the-first-dictionary-and-then-by-the-norm-of-the-second-dictionary" class="anchor" href="#define-a-function-cossim-that-returns-the-dot-product-of-two-dictionaries-divided-by-the-norm-of-the-first-dictionary-and-then-by-the-norm-of-the-second-dictionary" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Define a function <code>cossim</code>
 that returns the dot product of two dictionaries divided by the norm of
 the first dictionary and then by the norm of the second dictionary</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-3" class="anchor" href="#todo-replace--with-appropriate-code-3" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>import math</p>

<p>def dotprod(a, b):
    """ Compute dot product
    Args:
        a (dictionary): first dictionary of record to value
        b (dictionary): second dictionary of record to value
    Returns:
        dotProd: result of the dot product with the two input dictionaries
    """
    return </p>

<p>def norm(a):
    """ Compute square root of the dot product
    Args:
        a (dictionary): a dictionary of record to value
    Returns:
        norm: a dictionary of tokens to its TF values
    """
    return </p>

<p>def cossim(a, b):
    """ Compute cosine similarity
    Args:
        a (dictionary): first dictionary of record to value
        b (dictionary): second dictionary of record to value
    Returns:
        cossim: dot product of two dictionaries divided by the norm of the first dictionary and
                then by the norm of the second dictionary
    """
    return </p>

<p>testVec1 = {'foo': 2, 'bar': 3, 'baz': 5 }
testVec2 = {'foo': 1, 'bar': 0, 'baz': 20 }
dp = dotprod(testVec1, testVec2)
nm = norm(testVec1)
print dp, nm</p>

<h1><a id="user-content-test-implement-the-components-of-a-cosinesimilarity-function-3a" class="anchor" href="#test-implement-the-components-of-a-cosinesimilarity-function-3a" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Implement the components of a cosineSimilarity function (3a)</h1>

<p>Test.assertEquals(dp, 102, 'incorrect dp')
Test.assertTrue(abs(nm - 6.16441400297) &lt; 0.0000001, 'incorrrect nm')</p></li>
</ul>

<h3><a id="user-content-3b-implement-a-cosinesimilarity-function" class="anchor" href="#3b-implement-a-cosinesimilarity-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(3b) Implement a <code>cosineSimilarity</code> function</strong></h3>

<h4><a id="user-content-implement-a-cosinesimilaritystring1-string2-idfsdictionary-function-that-takes-two-strings-and-a-dictionary-of-idf-weights-and-computes-their-cosine-similarity-in-the-context-of-some-global-idf-weights" class="anchor" href="#implement-a-cosinesimilaritystring1-string2-idfsdictionary-function-that-takes-two-strings-and-a-dictionary-of-idf-weights-and-computes-their-cosine-similarity-in-the-context-of-some-global-idf-weights" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Implement a <code>cosineSimilarity(string1, string2, idfsDictionary)</code>
 function that takes two strings and a dictionary of IDF weights, and 
computes their cosine similarity in the context of some global IDF 
weights.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-1" class="anchor" href="#the-steps-you-should-perform-are-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Apply your <code>tfidf</code> function to the tokenized first and second strings, using the dictionary of IDF weights</li>
<li><h4><a id="user-content-compute-and-return-your-cossim-function-applied-to-the-results-of-the-two-tfidf-functions" class="anchor" href="#compute-and-return-your-cossim-function-applied-to-the-results-of-the-two-tfidf-functions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Compute and return your <code>cossim</code> function applied to the results of the two <code>tfidf</code> functions</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-4" class="anchor" href="#todo-replace--with-appropriate-code-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def cosineSimilarity(string1, string2, idfsDictionary):
    """ Compute cosine similarity between two strings
    Args:
        string1 (str): first string
        string2 (str): second string
        idfsDictionary (dictionary): a dictionary of IDF values
    Returns:
        cossim: cosine similarity value
    """
    w1 = tfidf()
    w2 = tfidf()
    return cossim(w1, w2)</p>

<p>cossimAdobe = cosineSimilarity('Adobe Photoshop',
                               'Adobe Illustrator',
                               idfsSmallWeights)</p>

<p>print cossimAdobe</p>

<h1><a id="user-content-test-implement-a-cosinesimilarity-function-3b" class="anchor" href="#test-implement-a-cosinesimilarity-function-3b" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Implement a cosineSimilarity function (3b)</h1>

<p>Test.assertTrue(abs(cossimAdobe - 0.0577243382163) &lt; 0.0000001, 'incorrect cossimAdobe')</p></li>
</ul>

<h3><a id="user-content-3c-perform-entity-resolution" class="anchor" href="#3c-perform-entity-resolution" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(3c) Perform Entity Resolution</strong></h3>

<h4><a id="user-content-now-we-can-finally-do-some-entity-resolution" class="anchor" href="#now-we-can-finally-do-some-entity-resolution" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Now we can finally do some entity resolution!</h4>

<h4><a id="user-content-for-every-product-record-in-the-small-google-dataset-use-your-cosinesimilarity-function-to-compute-its-similarity-to-every-record-in-the-small-amazon-dataset--then-build-a-dictionary-mapping-google-url-amazon-id-tuples-to-similarity-scores-between-0-and-1" class="anchor" href="#for-every-product-record-in-the-small-google-dataset-use-your-cosinesimilarity-function-to-compute-its-similarity-to-every-record-in-the-small-amazon-dataset--then-build-a-dictionary-mapping-google-url-amazon-id-tuples-to-similarity-scores-between-0-and-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>For <em>every</em> product record in the small Google dataset, use your <code>cosineSimilarity</code> function to compute its similarity to every record in the small Amazon dataset.  Then, build a dictionary mapping <code>(Google URL, Amazon ID)</code> tuples to similarity scores between 0 and 1.</h4>

<h4><a id="user-content-well-do-this-computation-two-different-ways-first-well-do-it-without-a-broadcast-variable-and-then-well-use-a-broadcast-variable" class="anchor" href="#well-do-this-computation-two-different-ways-first-well-do-it-without-a-broadcast-variable-and-then-well-use-a-broadcast-variable" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We'll
 do this computation two different ways, first we'll do it without a 
broadcast variable, and then we'll use a broadcast variable</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-2" class="anchor" href="#the-steps-you-should-perform-are-2" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Create an RDD that is a combination of the small Google and 
small Amazon datasets that has as elements all pairs of elements (a, b) 
where a is in self and b is in other. The result will be an RDD of the 
form: <code>[ ((Google URL1, Google String1), (Amazon ID1, Amazon 
String1)), ((Google URL1, Google String1), (Amazon ID2, Amazon 
String2)), ((Google URL2, Google String2), (Amazon ID1, Amazon 
String1)), ... ]</code></li>
<li>#### Define a worker function that given an element from the 
combination RDD computes the cosineSimlarity for the two records in the 
element</li>
<li><h4><a id="user-content-apply-the-worker-function-to-every-element-in-the-rdd" class="anchor" href="#apply-the-worker-function-to-every-element-in-the-rdd" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Apply the worker function to every element in the RDD</h4>

<h4><a id="user-content-now-compute-the-similarity-between-amazon-record-b000o24l3q-and-google-record-httpwwwgooglecombasefeedssnippets17242822440574356561" class="anchor" href="#now-compute-the-similarity-between-amazon-record-b000o24l3q-and-google-record-httpwwwgooglecombasefeedssnippets17242822440574356561" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Now, compute the similarity between Amazon record <code>b000o24l3q</code> and Google record <code>http://www.google.com/base/feeds/snippets/17242822440574356561</code>.</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-5" class="anchor" href="#todo-replace--with-appropriate-code-5" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>crossSmall = (googleSmall
              .
              .cache())</p>

<p>def computeSimilarity(record):
    """ Compute similarity on a combination record
    Args:
        record: a pair, (google record, amazon record)
    Returns:
        pair: a pair, (google URL, amazon ID, cosine similarity value)
    """
    googleRec = record[0]
    amazonRec = record[1]
    googleURL = 
    amazonID = 
    googleValue = 
    amazonValue = 
    cs = cosineSimilarity(, idfsSmallWeights)
    return (googleURL, amazonID, cs)</p>

<p>similarities = (crossSmall
                .
                .cache())</p>

<p>def similar(amazonID, googleURL):
    """ Return similarity value
    Args:
        amazonID: amazon ID
        googleURL: google URL
    Returns:
        similar: cosine similarity value
    """
    return (similarities
            .filter(lambda record: (record[0] == googleURL and record[1] == amazonID))
            .collect()[0][2])</p>

<p>similarityAmazonGoogle = similar('b000o24l3q', '<a href="http://www.google.com/base/feeds/snippets/17242822440574356561">http://www.google.com/base/feeds/snippets/17242822440574356561</a>')
print 'Requested similarity is %s.' % similarityAmazonGoogle</p>

<h1><a id="user-content-test-perform-entity-resolution-3c" class="anchor" href="#test-perform-entity-resolution-3c" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Perform Entity Resolution (3c)</h1>

<p>Test.assertTrue(abs(similarityAmazonGoogle - 0.000303171940451) &lt; 0.0000001,
                'incorrect similarityAmazonGoogle')</p></li>
</ul>

<h3><a id="user-content-3d-perform-entity-resolution-with-broadcast-variables" class="anchor" href="#3d-perform-entity-resolution-with-broadcast-variables" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(3d) Perform Entity Resolution with Broadcast Variables</strong></h3>

<h4><a id="user-content-the-solution-in-3c-works-well-for-small-datasets-but-it-requires-spark-to-automatically-send-the-idfssmallweights-variable-to-all-the-workers-if-we-didnt-cache-similarities-then-it-might-have-to-be-recreated-if-we-run-similar-multiple-times-this-would-cause-spark-to-send-idfssmallweights-every-time" class="anchor" href="#the-solution-in-3c-works-well-for-small-datasets-but-it-requires-spark-to-automatically-send-the-idfssmallweights-variable-to-all-the-workers-if-we-didnt-cache-similarities-then-it-might-have-to-be-recreated-if-we-run-similar-multiple-times-this-would-cause-spark-to-send-idfssmallweights-every-time" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The solution in (3c) works well for small datasets, but it requires Spark to (automatically) send the <code>idfsSmallWeights</code> variable to all the workers. If we didn't <code>cache()</code> similarities, then it might have to be recreated if we run <code>similar()</code> multiple times. This would cause Spark to send <code>idfsSmallWeights</code> every time.</h4>

<h4><a id="user-content-instead-we-can-use-a-broadcast-variable---we-define-the-broadcast-variable-in-the-driver-and-then-we-can-refer-to-it-in-each-worker-spark-saves-the-broadcast-variable-at-each-worker-so-it-is-only-sent-once" class="anchor" href="#instead-we-can-use-a-broadcast-variable---we-define-the-broadcast-variable-in-the-driver-and-then-we-can-refer-to-it-in-each-worker-spark-saves-the-broadcast-variable-at-each-worker-so-it-is-only-sent-once" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Instead,
 we can use a broadcast variable - we define the broadcast variable in 
the driver and then we can refer to it in each worker. Spark saves the 
broadcast variable at each worker, so it is only sent once.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-3" class="anchor" href="#the-steps-you-should-perform-are-3" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Define a <code>computeSimilarityBroadcast</code> function that 
given an element from the combination RDD computes the cosine simlarity 
for the two records in the element. This will be the same as the worker 
function <code>computeSimilarity</code> in (3c) except that it uses a broadcast variable.</li>
<li><h4><a id="user-content-apply-the-worker-function-to-every-element-in-the-rdd-1" class="anchor" href="#apply-the-worker-function-to-every-element-in-the-rdd-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Apply the worker function to every element in the RDD</h4>

<h4><a id="user-content-again-compute-the-similarity-between-amazon-record-b000o24l3q-and-google-record-httpwwwgooglecombasefeedssnippets17242822440574356561" class="anchor" href="#again-compute-the-similarity-between-amazon-record-b000o24l3q-and-google-record-httpwwwgooglecombasefeedssnippets17242822440574356561" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Again, compute the similarity between Amazon record <code>b000o24l3q</code> and Google record <code>http://www.google.com/base/feeds/snippets/17242822440574356561</code>.</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-6" class="anchor" href="#todo-replace--with-appropriate-code-6" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def computeSimilarityBroadcast(record):
    """ Compute similarity on a combination record, using Broadcast variable
    Args:
        record: a pair, (google record, amazon record)
    Returns:
        pair: a pair, (google URL, amazon ID, cosine similarity value)
    """
    googleRec = record[0]
    amazonRec = record[1]
    googleURL = 
    amazonID = 
    googleValue = 
    amazonValue = 
    cs = cosineSimilarity(, idfsSmallBroadcast.value)
    return (googleURL, amazonID, cs)</p>

<p>idfsSmallBroadcast = sc.broadcast(idfsSmallWeights)
similaritiesBroadcast = (crossSmall
                         .
                         .cache())</p>

<p>def similarBroadcast(amazonID, googleURL):
    """ Return similarity value, computed using Broadcast variable
    Args:
        amazonID: amazon ID
        googleURL: google URL
    Returns:
        similar: cosine similarity value
    """
    return (similaritiesBroadcast
            .filter(lambda record: (record[0] == googleURL and record[1] == amazonID))
            .collect()[0][2])</p>

<p>similarityAmazonGoogleBroadcast = similarBroadcast('b000o24l3q', '<a href="http://www.google.com/base/feeds/snippets/17242822440574356561">http://www.google.com/base/feeds/snippets/17242822440574356561</a>')
print 'Requested similarity is %s.' % similarityAmazonGoogleBroadcast</p>

<h1><a id="user-content-test-perform-entity-resolution-with-broadcast-variables-3d" class="anchor" href="#test-perform-entity-resolution-with-broadcast-variables-3d" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Perform Entity Resolution with Broadcast Variables (3d)</h1>

<p>from pyspark import Broadcast
Test.assertTrue(isinstance(idfsSmallBroadcast, Broadcast), 'incorrect idfsSmallBroadcast')
Test.assertEquals(len(idfsSmallBroadcast.value), 4772, 'incorrect idfsSmallBroadcast value')
Test.assertTrue(abs(similarityAmazonGoogleBroadcast - 0.000303171940451) &lt; 0.0000001,
                'incorrect similarityAmazonGoogle')</p></li>
</ul>

<h3><a id="user-content-3e-perform-a-gold-standard-evaluation" class="anchor" href="#3e-perform-a-gold-standard-evaluation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(3e) Perform a Gold Standard evaluation</strong></h3>

<h4><a id="user-content-first-well-load-the-gold-standard-data-and-use-it-to-answer-several-questions-we-read-and-parse-the-gold-standard-data-where-the-format-of-each-line-is-amazon-product-idgoogle-url-the-resulting-rdd-has-elements-of-the-form-amazonid-googleurl-gold" class="anchor" href="#first-well-load-the-gold-standard-data-and-use-it-to-answer-several-questions-we-read-and-parse-the-gold-standard-data-where-the-format-of-each-line-is-amazon-product-idgoogle-url-the-resulting-rdd-has-elements-of-the-form-amazonid-googleurl-gold" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>First,
 we'll load the "gold standard" data and use it to answer several 
questions. We read and parse the Gold Standard data, where the format of
 each line is "Amazon Product ID","Google URL". The resulting RDD has 
elements of the form ("AmazonID GoogleURL", 'gold')</h4>

<pre><code>GOLDFILE_PATTERN = '^(.+),(.+)'

# Parse each line of a data file useing the specified regular expression pattern
def parse_goldfile_line(goldfile_line):
    """ Parse a line from the 'golden standard' data file
    Args:
        goldfile_line: a line of data
    Returns:
        pair: ((key, 'gold', 1 if successful or else 0))
    """
    match = re.search(GOLDFILE_PATTERN, goldfile_line)
    if match is None:
        print 'Invalid goldfile line: %s' % goldfile_line
        return (goldfile_line, -1)
    elif match.group(1) == '"idAmazon"':
        print 'Header datafile line: %s' % goldfile_line
        return (goldfile_line, 0)
    else:
        key = '%s %s' % (removeQuotes(match.group(1)), removeQuotes(match.group(2)))
        return ((key, 'gold'), 1)

goldfile = os.path.join(baseDir, inputPath, GOLD_STANDARD_PATH)
gsRaw = (sc
         .textFile(goldfile)
         .map(parse_goldfile_line)
         .cache())

gsFailed = (gsRaw
            .filter(lambda s: s[1] == -1)
            .map(lambda s: s[0]))
for line in gsFailed.take(10):
    print 'Invalid goldfile line: %s' % line

goldStandard = (gsRaw
                .filter(lambda s: s[1] == 1)
                .map(lambda s: s[0])
                .cache())

print 'Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (gsRaw.count(),
                                                                                 goldStandard.count(),
                                                                                 gsFailed.count())
assert (gsFailed.count() == 0)
assert (gsRaw.count() == (goldStandard.count() + 1))
</code></pre>

<h3><a id="user-content-using-the-gold-standard-data-we-can-answer-the-following-questions" class="anchor" href="#using-the-gold-standard-data-we-can-answer-the-following-questions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Using the "gold standard" data we can answer the following questions:</h3>

<ul>
<li>#### How many true duplicate pairs are there in the small datasets?</li>
<li>#### What is the average similarity score for true duplicates?</li>
<li>#### What about for non-duplicates?
#### The steps you should perform are:</li>
<li>#### Create a new <code>sims</code> RDD from the <code>similaritiesBroadcast</code> RDD, where each element consists of a pair of the form ("AmazonID GoogleURL", cosineSimilarityScore). An example entry from <code>sims</code> is: ('b000bi7uqs <a href="http://www.google.com/base/feeds/snippets/18403148885652932189">http://www.google.com/base/feeds/snippets/18403148885652932189</a>', 0.40202896125621296)</li>
<li>#### Combine the <code>sims</code> RDD with the <code>goldStandard</code> RDD by creating a new <code>trueDupsRDD</code> RDD that has the just the cosine similarity scores for those "AmazonID GoogleURL" pairs that appear in both the <code>sims</code> RDD and <code>goldStandard</code> RDD. Hint: you can do this using the join() transformation.</li>
<li>#### Count the number of true duplicate pairs in the <code>trueDupsRDD</code> dataset</li>
<li>#### Compute the average similarity score for true duplicates in the <code>trueDupsRDD</code> datasets. Remember to use <code>float</code> for calculation</li>
<li>#### Create a new <code>nonDupsRDD</code> RDD that has the just the cosine similarity scores for those "AmazonID GoogleURL" pairs from the <code>similaritiesBroadcast</code> RDD that <strong>do not</strong> appear in both the <em>sims</em> RDD and gold standard RDD.</li>
<li><h4><a id="user-content-compute-the-average-similarity-score-for-non-duplicates-in-the-last-datasets-remember-to-use-float-for-calculation" class="anchor" href="#compute-the-average-similarity-score-for-non-duplicates-in-the-last-datasets-remember-to-use-float-for-calculation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Compute the average similarity score for non-duplicates in the last datasets. Remember to use <code>float</code> for calculation</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-7" class="anchor" href="#todo-replace--with-appropriate-code-7" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>sims = similaritiesBroadcast.)</p>

<p>trueDupsRDD = (sims
               .)
trueDupsCount = trueDupsRDD.
avgSimDups = </p>

<p>nonDupsRDD = (sims
              .)
avgSimNon = </p>

<p>print 'There are %s true duplicates.' % trueDupsCount
print 'The average similarity of true duplicates is %s.' % avgSimDups
print 'And for non duplicates, it is %s.' % avgSimNon</p>

<h1><a id="user-content-test-perform-a-gold-standard-evaluation-3e" class="anchor" href="#test-perform-a-gold-standard-evaluation-3e" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Perform a Gold Standard evaluation (3e)</h1>

<p>Test.assertEquals(trueDupsCount, 146, 'incorrect trueDupsCount')
Test.assertTrue(abs(avgSimDups - 0.264332573435) &lt; 0.0000001, 'incorrect avgSimDups')
Test.assertTrue(abs(avgSimNon - 0.00123476304656) &lt; 0.0000001, 'incorrect avgSimNon')</p></li>
</ul>

<h3><a id="user-content-part-4-scalable-er" class="anchor" href="#part-4-scalable-er" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Part 4: Scalable ER</strong></h3>

<h4><a id="user-content-in-the-previous-parts-we-built-a-text-similarity-function-and-used-it-for-small-scale-entity-resolution--our-implementation-is-limited-by-its-quadratic-run-time-complexity-and-is-not-practical-for-even-modestly-sized-datasets--in-this-part-we-will-implement-a-more-scalable-algorithm-and-use-it-to-do-entity-resolution-on-the-full-dataset" class="anchor" href="#in-the-previous-parts-we-built-a-text-similarity-function-and-used-it-for-small-scale-entity-resolution--our-implementation-is-limited-by-its-quadratic-run-time-complexity-and-is-not-practical-for-even-modestly-sized-datasets--in-this-part-we-will-implement-a-more-scalable-algorithm-and-use-it-to-do-entity-resolution-on-the-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>In
 the previous parts, we built a text similarity function and used it for
 small scale entity resolution.  Our implementation is limited by its 
quadratic run time complexity, and is not practical for even modestly 
sized datasets.  In this part, we will implement a more scalable 
algorithm and use it to do entity resolution on the full dataset.</h4>

<h3><a id="user-content-inverted-indices" class="anchor" href="#inverted-indices" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Inverted Indices</h3>

<h4><a id="user-content-to-improve-our-er-algorithm-from-the-earlier-parts-we-should-begin-by-analyzing-its-running-time-in-particular-the-algorithm-above-is-quadratic-in-two-ways-first-we-did-a-lot-of-redundant-computation-of-tokens-and-weights-since-each-record-was-reprocessed-every-time-it-was-compared-second-we-made-quadratically-many-token-comparisons-between-records" class="anchor" href="#to-improve-our-er-algorithm-from-the-earlier-parts-we-should-begin-by-analyzing-its-running-time-in-particular-the-algorithm-above-is-quadratic-in-two-ways-first-we-did-a-lot-of-redundant-computation-of-tokens-and-weights-since-each-record-was-reprocessed-every-time-it-was-compared-second-we-made-quadratically-many-token-comparisons-between-records" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>To
 improve our ER algorithm from the earlier parts, we should begin by 
analyzing its running time. In particular, the algorithm above is 
quadratic in two ways. First, we did a lot of redundant computation of 
tokens and weights, since each record was reprocessed every time it was 
compared. Second, we made quadratically many token comparisons between 
records.</h4>

<h4><a id="user-content-the-first-source-of-quadratic-overhead-can-be-eliminated-with-precomputation-and-look-up-tables-but-the-second-source-is-a-little-more-tricky-in-the-worst-case-every-token-in-every-record-in-one-dataset-exists-in-every-record-in-the-other-dataset-and-therefore-every-token-makes-a-non-zero-contribution-to-the-cosine-similarity-in-this-case-token-comparison-is-unavoidably-quadratic" class="anchor" href="#the-first-source-of-quadratic-overhead-can-be-eliminated-with-precomputation-and-look-up-tables-but-the-second-source-is-a-little-more-tricky-in-the-worst-case-every-token-in-every-record-in-one-dataset-exists-in-every-record-in-the-other-dataset-and-therefore-every-token-makes-a-non-zero-contribution-to-the-cosine-similarity-in-this-case-token-comparison-is-unavoidably-quadratic" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The
 first source of quadratic overhead can be eliminated with 
precomputation and look-up tables, but the second source is a little 
more tricky. In the worst case, every token in every record in one 
dataset exists in every record in the other dataset, and therefore every
 token makes a non-zero contribution to the cosine similarity. In this 
case, token comparison is unavoidably quadratic.</h4>

<h4><a id="user-content-but-in-reality-most-records-have-nothing-or-very-little-in-common-moreover-it-is-typical-for-a-record-in-one-dataset-to-have-at-most-one-duplicate-record-in-the-other-dataset-this-is-the-case-assuming-each-dataset-has-been-de-duplicated-against-itself-in-this-case-the-output-is-linear-in-the-size-of-the-input-and-we-can-hope-to-achieve-linear-running-time" class="anchor" href="#but-in-reality-most-records-have-nothing-or-very-little-in-common-moreover-it-is-typical-for-a-record-in-one-dataset-to-have-at-most-one-duplicate-record-in-the-other-dataset-this-is-the-case-assuming-each-dataset-has-been-de-duplicated-against-itself-in-this-case-the-output-is-linear-in-the-size-of-the-input-and-we-can-hope-to-achieve-linear-running-time" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>But
 in reality most records have nothing (or very little) in common. 
Moreover, it is typical for a record in one dataset to have at most one 
duplicate record in the other dataset (this is the case assuming each 
dataset has been de-duplicated against itself). In this case, the output
 is linear in the size of the input and we can hope to achieve linear 
running time.</h4>

<h4><a id="user-content-an-inverted-index-is-a-data-structure-that-will-allow-us-to-avoid-making-quadratically-many-token-comparisons--it-maps-each-token-in-the-dataset-to-the-list-of-documents-that-contain-the-token--so-instead-of-comparing-record-by-record-each-token-to-every-other-token-to-see-if-they-match-we-will-use-inverted-indices-to-look-up-records-that-match-on-a-particular-token" class="anchor" href="#an-inverted-index-is-a-data-structure-that-will-allow-us-to-avoid-making-quadratically-many-token-comparisons--it-maps-each-token-in-the-dataset-to-the-list-of-documents-that-contain-the-token--so-instead-of-comparing-record-by-record-each-token-to-every-other-token-to-see-if-they-match-we-will-use-inverted-indices-to-look-up-records-that-match-on-a-particular-token" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>An <a href="https://en.wikipedia.org/wiki/Inverted_index"><strong>inverted index</strong></a>
 is a data structure that will allow us to avoid making quadratically 
many token comparisons.  It maps each token in the dataset to the list 
of documents that contain the token.  So, instead of comparing, record 
by record, each token to every other token to see if they match, we will
 use inverted indices to <em>look up</em> records that match on a particular token.</h4>

<blockquote>
<h4><a id="user-content-note-on-terminology-in-text-search-a-forward-index-maps-documents-in-a-dataset-to-the-tokens-they-contain--an-inverted-index-supports-the-inverse-mapping" class="anchor" href="#note-on-terminology-in-text-search-a-forward-index-maps-documents-in-a-dataset-to-the-tokens-they-contain--an-inverted-index-supports-the-inverse-mapping" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Note on terminology</strong>: In text search, a <em>forward</em> index maps documents in a dataset to the tokens they contain.  An <em>inverted</em> index supports the inverse mapping.</h4>

<h4><a id="user-content-note-for-this-section-use-the-complete-google-and-amazon-datasets-not-the-samples" class="anchor" href="#note-for-this-section-use-the-complete-google-and-amazon-datasets-not-the-samples" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Note</strong>: For this section, use the complete Google and Amazon datasets, not the samples</h4>
</blockquote>

<h3><a id="user-content-4a-tokenize-the-full-dataset" class="anchor" href="#4a-tokenize-the-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(4a) Tokenize the full dataset</strong></h3>

<h4><a id="user-content-tokenize-each-of-the-two-full-datasets-for-google-and-amazon" class="anchor" href="#tokenize-each-of-the-two-full-datasets-for-google-and-amazon" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Tokenize each of the two full datasets for Google and Amazon.</h4>

<pre><code># TODO: Replace &lt;FILL IN&gt; with appropriate code
amazonFullRecToToken = amazon.&lt;FILL IN&gt;
googleFullRecToToken = google.&lt;FILL IN&gt;
print 'Amazon full dataset is %s products, Google full dataset is %s products' % (amazonFullRecToToken.count(),
                                                                                    googleFullRecToToken.count())


# TEST Tokenize the full dataset (4a)
Test.assertEquals(amazonFullRecToToken.count(), 1363, 'incorrect amazonFullRecToToken.count()')
Test.assertEquals(googleFullRecToToken.count(), 3226, 'incorrect googleFullRecToToken.count()')
</code></pre>

<h3><a id="user-content-4b-compute-idfs-and-tf-idfs-for-the-full-datasets" class="anchor" href="#4b-compute-idfs-and-tf-idfs-for-the-full-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(4b) Compute IDFs and TF-IDFs for the full datasets</strong></h3>

<h4><a id="user-content-we-will-reuse-your-code-from-above-to-compute-idf-weights-for-the-complete-combined-datasets" class="anchor" href="#we-will-reuse-your-code-from-above-to-compute-idf-weights-for-the-complete-combined-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We will reuse your code from above to compute IDF weights for the complete combined datasets.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-4" class="anchor" href="#the-steps-you-should-perform-are-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Create a new <code>fullCorpusRDD</code> that contains the tokens from the full Amazon and Google datasets.</li>
<li>#### Apply your <code>idfs</code> function to the <code>fullCorpusRDD</code></li>
<li>#### Create a broadcast variable containing a dictionary of the IDF weights for the full dataset.</li>
<li><h4><a id="user-content-for-each-of-the-amazon-and-google-full-datasets-create-weight-rdds-that-map-idsurls-to-tf-idf-weighted-token-vectors" class="anchor" href="#for-each-of-the-amazon-and-google-full-datasets-create-weight-rdds-that-map-idsurls-to-tf-idf-weighted-token-vectors" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>For each of the Amazon and Google full datasets, create weight RDDs that map IDs/URLs to TF-IDF weighted token vectors.</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-8" class="anchor" href="#todo-replace--with-appropriate-code-8" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>fullCorpusRDD = 
idfsFull = idfs(fullCorpusRDD)
idfsFullCount = idfsFull.count()
print 'There are %s unique tokens in the full datasets.' % idfsFullCount</p>

<h1><a id="user-content-recompute-idfs-for-full-dataset" class="anchor" href="#recompute-idfs-for-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Recompute IDFs for full dataset</h1>

<p>idfsFullWeights = 
idfsFullBroadcast = </p>

<h1><a id="user-content-pre-compute-tf-idf-weights--build-mappings-from-record-id-weight-vector" class="anchor" href="#pre-compute-tf-idf-weights--build-mappings-from-record-id-weight-vector" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Pre-compute TF-IDF weights.  Build mappings from record ID weight vector.</h1>

<p>amazonWeightsRDD = 
googleWeightsRDD = 
print 'There are %s Amazon weights and %s Google weights.' % (amazonWeightsRDD.count(),
                                                              googleWeightsRDD.count())</p>

<h1><a id="user-content-test-compute-idfs-and-tf-idfs-for-the-full-datasets-4b" class="anchor" href="#test-compute-idfs-and-tf-idfs-for-the-full-datasets-4b" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Compute IDFs and TF-IDFs for the full datasets (4b)</h1>

<p>Test.assertEquals(idfsFullCount, 17078, 'incorrect idfsFullCount')
Test.assertEquals(amazonWeightsRDD.count(), 1363, 'incorrect amazonWeightsRDD.count()')
Test.assertEquals(googleWeightsRDD.count(), 3226, 'incorrect googleWeightsRDD.count()')</p></li>
</ul>

<h3><a id="user-content-4c-compute-norms-for-the-weights-from-the-full-datasets" class="anchor" href="#4c-compute-norms-for-the-weights-from-the-full-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(4c) Compute Norms for the weights from the full datasets</strong></h3>

<h4><a id="user-content-we-will-reuse-your-code-from-above-to-compute-norms-of-the-idf-weights-for-the-complete-combined-dataset" class="anchor" href="#we-will-reuse-your-code-from-above-to-compute-norms-of-the-idf-weights-for-the-complete-combined-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We will reuse your code from above to compute norms of the IDF weights for the complete combined dataset.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-5" class="anchor" href="#the-steps-you-should-perform-are-5" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Create two collections, one for each of the full Amazon and 
Google datasets, where IDs/URLs map to the norm of the associated TF-IDF
 weighted token vectors.</li>
<li><h4><a id="user-content-convert-each-collection-into-a-broadcast-variable-containing-a-dictionary-of-the-norm-of-idf-weights-for-the-full-dataset" class="anchor" href="#convert-each-collection-into-a-broadcast-variable-containing-a-dictionary-of-the-norm-of-idf-weights-for-the-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Convert each collection into a broadcast variable, containing a dictionary of the norm of IDF weights for the full dataset</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-9" class="anchor" href="#todo-replace--with-appropriate-code-9" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>amazonNorms = amazonWeightsRDD.
amazonNormsBroadcast = 
googleNorms = googleWeightsRDD.
googleNormsBroadcast = </p>

<h1><a id="user-content-test-compute-norms-for-the-weights-from-the-full-datasets-4c" class="anchor" href="#test-compute-norms-for-the-weights-from-the-full-datasets-4c" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Compute Norms for the weights from the full datasets (4c)</h1>

<p>Test.assertTrue(isinstance(amazonNormsBroadcast, Broadcast), 'incorrect amazonNormsBroadcast')
Test.assertEquals(len(amazonNormsBroadcast.value), 1363, 'incorrect amazonNormsBroadcast.value')
Test.assertTrue(isinstance(googleNormsBroadcast, Broadcast), 'incorrect googleNormsBroadcast')
Test.assertEquals(len(googleNormsBroadcast.value), 3226, 'incorrect googleNormsBroadcast.value')</p></li>
</ul>

<h3><a id="user-content-4d-create-inverted-indicies-from-the-full-datasets" class="anchor" href="#4d-create-inverted-indicies-from-the-full-datasets" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(4d) Create inverted indicies from the full datasets</strong></h3>

<h4><a id="user-content-build-inverted-indices-of-both-data-sources" class="anchor" href="#build-inverted-indices-of-both-data-sources" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Build inverted indices of both data sources.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-6" class="anchor" href="#the-steps-you-should-perform-are-6" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Create an invert function that given a pair of (ID/URL, TF-IDF 
weighted token vector), returns a list of pairs of (token, ID/URL). 
Recall that the TF-IDF weighted token vector is a Python dictionary with
 keys that are tokens and values that are weights.</li>
<li><h4><a id="user-content-use-your-invert-function-to-convert-the-full-amazon-and-google-tf-idf-weighted-token-vector-datasets-into-two-rdds-where-each-element-is-a-pair-of-a-token-and-an-idurl-that-contain-that-token-these-are-inverted-indicies" class="anchor" href="#use-your-invert-function-to-convert-the-full-amazon-and-google-tf-idf-weighted-token-vector-datasets-into-two-rdds-where-each-element-is-a-pair-of-a-token-and-an-idurl-that-contain-that-token-these-are-inverted-indicies" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Use
 your invert function to convert the full Amazon and Google TF-IDF 
weighted token vector datasets into two RDDs where each element is a 
pair of a token and an ID/URL that contain that token. These are 
inverted indicies.</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-10" class="anchor" href="#todo-replace--with-appropriate-code-10" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def invert(record):
    """ Invert (ID, tokens) to a list of (token, ID)
    Args:
        record: a pair, (ID, token vector)
    Returns:
        pairs: a list of pairs of token to ID
    """
    
    return (pairs)</p>

<p>amazonInvPairsRDD = (amazonWeightsRDD
                    .
                    .cache())</p>

<p>googleInvPairsRDD = (googleWeightsRDD
                    .
                    .cache())</p>

<p>print 'There are %s Amazon inverted pairs and %s Google inverted pairs.' % (amazonInvPairsRDD.count(),
                                                                            googleInvPairsRDD.count())</p>

<h1><a id="user-content-test-create-inverted-indicies-from-the-full-datasets-4d" class="anchor" href="#test-create-inverted-indicies-from-the-full-datasets-4d" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Create inverted indicies from the full datasets (4d)</h1>

<p>invertedPair = invert((1, {'foo': 2}))
Test.assertEquals(invertedPair[0][1], 1, 'incorrect invert result')
Test.assertEquals(amazonInvPairsRDD.count(), 111387, 'incorrect amazonInvPairsRDD.count()')
Test.assertEquals(googleInvPairsRDD.count(), 77678, 'incorrect googleInvPairsRDD.count()')</p></li>
</ul>

<h3><a id="user-content-4e-identify-common-tokens-from-the-full-dataset" class="anchor" href="#4e-identify-common-tokens-from-the-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(4e) Identify common tokens from the full dataset</strong></h3>

<h4><a id="user-content-we-are-now-in-position-to-efficiently-perform-er-on-the-full-datasets-implement-the-following-algorithm-to-build-an-rdd-that-maps-a-pair-of-id-url-to-a-list-of-tokens-they-share-in-common" class="anchor" href="#we-are-now-in-position-to-efficiently-perform-er-on-the-full-datasets-implement-the-following-algorithm-to-build-an-rdd-that-maps-a-pair-of-id-url-to-a-list-of-tokens-they-share-in-common" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We
 are now in position to efficiently perform ER on the full datasets. 
Implement the following algorithm to build an RDD that maps a pair of 
(ID, URL) to a list of tokens they share in common:</h4>

<ul>
<li>#### Using the two inverted indicies (RDDs where each element is a 
pair of a token and an ID or URL that contains that token), create a new
 RDD that contains only tokens that appear in both datasets. This will 
yield an RDD of pairs of (token, iterable(ID, URL)).</li>
<li>#### We need a mapping from (ID, URL) to token, so create a function
 that will swap the elements of the RDD you just created to create this 
new RDD consisting of ((ID, URL), token) pairs.</li>
<li><h4><a id="user-content-finally-create-an-rdd-consisting-of-pairs-mapping-id-url-to-all-the-tokens-the-pair-shares-in-common" class="anchor" href="#finally-create-an-rdd-consisting-of-pairs-mapping-id-url-to-all-the-tokens-the-pair-shares-in-common" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Finally, create an RDD consisting of pairs mapping (ID, URL) to all the tokens the pair shares in common</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-11" class="anchor" href="#todo-replace--with-appropriate-code-11" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>def swap(record):
    """ Swap (token, (ID, URL)) to ((ID, URL), token)
    Args:
        record: a pair, (token, (ID, URL))
    Returns:
        pair: ((ID, URL), token)
    """
    token = 
    keys = 
    return (keys, token)</p>

<p>commonTokens = (amazonInvPairsRDD
                .
                .cache())</p>

<p>print 'Found %d common tokens' % commonTokens.count()</p>

<h1><a id="user-content-test-identify-common-tokens-from-the-full-dataset-4e" class="anchor" href="#test-identify-common-tokens-from-the-full-dataset-4e" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Identify common tokens from the full dataset (4e)</h1>

<p>Test.assertEquals(commonTokens.count(), 2441100, 'incorrect commonTokens.count()')</p></li>
</ul>

<h3><a id="user-content-4f-identify-common-tokens-from-the-full-dataset" class="anchor" href="#4f-identify-common-tokens-from-the-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(4f) Identify common tokens from the full dataset</strong></h3>

<h4><a id="user-content-use-the-data-structures-from-parts-4a-and-4e-to-build-a-dictionary-to-map-record-pairs-to-cosine-similarity-scores" class="anchor" href="#use-the-data-structures-from-parts-4a-and-4e-to-build-a-dictionary-to-map-record-pairs-to-cosine-similarity-scores" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Use the data structures from parts <strong>(4a)</strong> and <strong>(4e)</strong> to build a dictionary to map record pairs to cosine similarity scores.</h4>

<h4><a id="user-content-the-steps-you-should-perform-are-7" class="anchor" href="#the-steps-you-should-perform-are-7" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The steps you should perform are:</h4>

<ul>
<li>#### Create two broadcast dictionaries from the amazonWeights and googleWeights RDDs</li>
<li>#### Create a <code>fastCosinesSimilarity</code> function that takes
 in a record consisting of the pair ((Amazon ID, Google URL), tokens 
list) and computes the sum for each of the tokens in the token list of 
the products of the Amazon weight for the token times the Google weight 
for the token. The sum should then be divided by the norm for the Google
 URL and then divided by the norm for the Amazon ID. The function should
 return this value in a pair with the key being the (Amazon ID, Google 
URL). <em>Make sure you use broadcast variables you created for both the weights and norms</em></li>
<li><h4><a id="user-content-apply-your-fastcosinessimilarity-function-to-the-common-tokens-from-the-full-dataset" class="anchor" href="#apply-your-fastcosinessimilarity-function-to-the-common-tokens-from-the-full-dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Apply your <code>fastCosinesSimilarity</code> function to the common tokens from the full dataset</h4>

<h1><a id="user-content-todo-replace--with-appropriate-code-12" class="anchor" href="#todo-replace--with-appropriate-code-12" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TODO: Replace  with appropriate code</h1>

<p>amazonWeightsBroadcast = 
googleWeightsBroadcast = </p>

<p>def fastCosineSimilarity(record):
    """ Compute Cosine Similarity using Broadcast variables
    Args:
        record: ((ID, URL), token)
    Returns:
        pair: ((ID, URL), cosine similarity value)
    """
    amazonRec = 
    googleRec = 
    tokens = 
    s = 
    value = 
    key = (amazonRec, googleRec)
    return (key, value)</p>

<p>similaritiesFullRDD = (commonTokens
                       .
                       .cache())</p>

<p>print similaritiesFullRDD.count()</p>

<h1><a id="user-content-test-identify-common-tokens-from-the-full-dataset-4f" class="anchor" href="#test-identify-common-tokens-from-the-full-dataset-4f" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>TEST Identify common tokens from the full dataset (4f)</h1>

<p>similarityTest = similaritiesFullRDD.filter(lambda ((aID, gURL), cs): aID == 'b00005lzly' and gURL == '<a href="http://www.google.com/base/feeds/snippets/13823221823254120257%27%29.collect%28">http://www.google.com/base/feeds/snippets/13823221823254120257').collect(</a>)
Test.assertEquals(len(similarityTest), 1, 'incorrect 
len(similarityTest)')
Test.assertTrue(abs(similarityTest[0][1] - 4.286548414e-06) &lt; 
0.000000000001, 'incorrect similarityTest fastCosineSimilarity')
Test.assertEquals(similaritiesFullRDD.count(), 2441100, 'incorrect 
similaritiesFullRDD.count()')</p></li>
</ul>

<h3><a id="user-content-part-5-analysis" class="anchor" href="#part-5-analysis" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Part 5: Analysis</strong></h3>

<h4><a id="user-content-now-we-have-an-authoritative-list-of-record-pair-similarities-but-we-need-a-way-to-use-those-similarities-to-decide-if-two-records-are-duplicates-or-not-the-simplest-approach-is-to-pick-a-threshold-pairs-whose-similarity-is-above-the-threshold-are-declared-duplicates-and-pairs-below-the-threshold-are-declared-distinct" class="anchor" href="#now-we-have-an-authoritative-list-of-record-pair-similarities-but-we-need-a-way-to-use-those-similarities-to-decide-if-two-records-are-duplicates-or-not-the-simplest-approach-is-to-pick-a-threshold-pairs-whose-similarity-is-above-the-threshold-are-declared-duplicates-and-pairs-below-the-threshold-are-declared-distinct" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Now
 we have an authoritative list of record-pair similarities, but we need a
 way to use those similarities to decide if two records are duplicates 
or not. The simplest approach is to pick a <strong>threshold</strong>. Pairs whose similarity is above the threshold are declared duplicates, and pairs below the threshold are declared distinct.</h4>

<h4><a id="user-content-to-decide-where-to-set-the-threshold-we-need-to-understand-what-kind-of-errors-result-at-different-levels-if-we-set-the-threshold-too-low-we-get-more-false-positives-that-is-record-pairs-we-say-are-duplicates-that-in-reality-are-not-if-we-set-the-threshold-too-high-we-get-more-false-negatives-that-is-record-pairs-that-really-are-duplicates-but-that-we-miss" class="anchor" href="#to-decide-where-to-set-the-threshold-we-need-to-understand-what-kind-of-errors-result-at-different-levels-if-we-set-the-threshold-too-low-we-get-more-false-positives-that-is-record-pairs-we-say-are-duplicates-that-in-reality-are-not-if-we-set-the-threshold-too-high-we-get-more-false-negatives-that-is-record-pairs-that-really-are-duplicates-but-that-we-miss" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>To
 decide where to set the threshold we need to understand what kind of 
errors result at different levels. If we set the threshold too low, we 
get more <strong>false positives</strong>, that is, record-pairs we say are duplicates that in reality are not. If we set the threshold too high, we get more <strong>false negatives</strong>, that is, record-pairs that really are duplicates but that we miss.</h4>

<h4><a id="user-content-er-algorithms-are-evaluated-by-the-common-metrics-of-information-retrieval-and-search-called-precision-and-recall-precision-asks-of-all-the-record-pairs-marked-duplicates-what-fraction-are-true-duplicates-recall-asks-of-all-the-true-duplicates-in-the-data-what-fraction-did-we-successfully-find-as-with-false-positives-and-false-negatives-there-is-a-trade-off-between-precision-and-recall-a-third-metric-called-f-measure-takes-the-harmonic-mean-of-precision-and-recall-to-measure-overall-goodness-in-a-single-value" class="anchor" href="#er-algorithms-are-evaluated-by-the-common-metrics-of-information-retrieval-and-search-called-precision-and-recall-precision-asks-of-all-the-record-pairs-marked-duplicates-what-fraction-are-true-duplicates-recall-asks-of-all-the-true-duplicates-in-the-data-what-fraction-did-we-successfully-find-as-with-false-positives-and-false-negatives-there-is-a-trade-off-between-precision-and-recall-a-third-metric-called-f-measure-takes-the-harmonic-mean-of-precision-and-recall-to-measure-overall-goodness-in-a-single-value" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>ER algorithms are evaluated by the common metrics of information retrieval and search called <strong>precision</strong> and <strong>recall</strong>.
 Precision asks of all the record-pairs marked duplicates, what fraction
 are true duplicates? Recall asks of all the true duplicates in the 
data, what fraction did we successfully find? As with false positives 
and false negatives, there is a trade-off between precision and recall. A
 third metric, called <strong>F-measure</strong>, takes the harmonic mean of precision and recall to measure overall goodness in a single value:</h4>

<h4><a id="user-content--fmeasure--2-fracprecision--recallprecision--recall-" class="anchor" href="#-fmeasure--2-fracprecision--recallprecision--recall-" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>$$ Fmeasure = 2 \frac{precision * recall}{precision + recall} $$</h4>

<blockquote>
<h4><a id="user-content-note-in-this-part-we-use-the-gold-standard-mapping-from-the-included-file-to-look-up-true-duplicates-and-the-results-of-part-4" class="anchor" href="#note-in-this-part-we-use-the-gold-standard-mapping-from-the-included-file-to-look-up-true-duplicates-and-the-results-of-part-4" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Note</strong>: In this part, we use the "gold standard" mapping from the included file to look up true duplicates, and the results of Part 4.</h4>

<h4><a id="user-content-note-in-this-part-you-will-not-be-writing-any-code-weve-written-all-of-the-code-for-you-run-each-cell-and-then-answer-the-quiz-questions-on-studio" class="anchor" href="#note-in-this-part-you-will-not-be-writing-any-code-weve-written-all-of-the-code-for-you-run-each-cell-and-then-answer-the-quiz-questions-on-studio" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>Note</strong>:
 In this part, you will not be writing any code. We've written all of 
the code for you. Run each cell and then answer the quiz questions on 
Studio.</h4>
</blockquote>

<h3><a id="user-content-5a-counting-true-positives-false-positives-and-false-negatives" class="anchor" href="#5a-counting-true-positives-false-positives-and-false-negatives" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(5a) Counting True Positives, False Positives, and False Negatives</strong></h3>

<h4><a id="user-content-we-need-functions-that-count-true-positives-true-duplicates-above-the-threshold-and-false-positives-and-false-negatives" class="anchor" href="#we-need-functions-that-count-true-positives-true-duplicates-above-the-threshold-and-false-positives-and-false-negatives" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We need functions that count True Positives (true duplicates above the threshold), and False Positives and False Negatives:</h4>

<ul>
<li>#### We start with creating the <code>simsFullRDD</code> from our <code>similaritiesFullRDD</code> that consists of a pair of ((Amazon ID, Google URL), simlarity score)</li>
<li>#### From this RDD, we create an RDD consisting of only the similarity scores</li>
<li><h4><a id="user-content-to-look-up-the-similarity-scores-for-true-duplicates-we-perform-a-left-outer-join-using-the-goldstandard-rdd-and-simsfullrdd-and-extract-the" class="anchor" href="#to-look-up-the-similarity-scores-for-true-duplicates-we-perform-a-left-outer-join-using-the-goldstandard-rdd-and-simsfullrdd-and-extract-the" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>To look up the similarity scores for true duplicates, we perform a left outer join using the <code>goldStandard</code> RDD and <code>simsFullRDD</code> and extract the</h4>

<h1><a id="user-content-create-an-rdd-of-amazon-id-google-url-similarity-score" class="anchor" href="#create-an-rdd-of-amazon-id-google-url-similarity-score" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Create an RDD of ((Amazon ID, Google URL), similarity score)</h1>

<p>simsFullRDD = similaritiesFullRDD.map(lambda x: ("%s %s" % (x[0][0], x[0][1]), x[1]))
assert (simsFullRDD.count() == 2441100)</p>

<h1><a id="user-content-create-an-rdd-of-just-the-similarity-scores" class="anchor" href="#create-an-rdd-of-just-the-similarity-scores" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Create an RDD of just the similarity scores</h1>

<p>simsFullValuesRDD = (simsFullRDD
                     .map(lambda x: x[1])
                     .cache())
assert (simsFullValuesRDD.count() == 2441100)</p>

<h1><a id="user-content-look-up-all-similarity-scores-for-true-duplicates" class="anchor" href="#look-up-all-similarity-scores-for-true-duplicates" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Look up all similarity scores for true duplicates</h1>

<h1><a id="user-content-this-helper-function-will-return-the-similarity-score-for-records-that-are-in-the-gold-standard-and-the-simsfullrdd-true-positives-and-will-return-0-for-records-that-are-in-the-gold-standard-but-not-in-simsfullrdd-false-negatives" class="anchor" href="#this-helper-function-will-return-the-similarity-score-for-records-that-are-in-the-gold-standard-and-the-simsfullrdd-true-positives-and-will-return-0-for-records-that-are-in-the-gold-standard-but-not-in-simsfullrdd-false-negatives" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>This
 helper function will return the similarity score for records that are 
in the gold standard and the simsFullRDD (True positives), and will 
return 0 for records that are in the gold standard but not in 
simsFullRDD (False Negatives).</h1>

<p>def gs_value(record):
    if (record[1][1] is None):
        return 0
    else:
        return record[1][1]</p>

<h1><a id="user-content-join-the-gold-standard-and-simsfullrdd-and-then-extract-the-similarities-scores-using-the-helper-function" class="anchor" href="#join-the-gold-standard-and-simsfullrdd-and-then-extract-the-similarities-scores-using-the-helper-function" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Join the gold standard and simsFullRDD, and then extract the similarities scores using the helper function</h1>

<p>trueDupSimsRDD = (goldStandard
                  .leftOuterJoin(simsFullRDD)
                  .map(gs_value)
                  .cache())
print 'There are %s true duplicates.' % trueDupSimsRDD.count()
assert(trueDupSimsRDD.count() == 1300)</p></li>
</ul>

<h4><a id="user-content-the-next-step-is-to-pick-a-threshold-between-0-and-1-for-the-count-of-true-positives-true-duplicates-above-the-threshold-however-we-would-like-to-explore-many-different-thresholds-to-do-this-we-divide-the-space-of-thresholds-into-100-bins-and-take-the-following-actions" class="anchor" href="#the-next-step-is-to-pick-a-threshold-between-0-and-1-for-the-count-of-true-positives-true-duplicates-above-the-threshold-however-we-would-like-to-explore-many-different-thresholds-to-do-this-we-divide-the-space-of-thresholds-into-100-bins-and-take-the-following-actions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>The
 next step is to pick a threshold between 0 and 1 for the count of True 
Positives (true duplicates above the threshold). However, we would like 
to explore many different thresholds. To do this, we divide the space of
 thresholds into 100 bins, and take the following actions:</h4>

<ul>
<li>#### We use Spark Accumulators to implement our counting function. We define a custom accumulator type, <code>VectorAccumulatorParam</code>,
 along with functions to initialize the accumulator's vector to zero, 
and to add two vectors. Note that we have to use the += operator because
 you can only add to an accumulator.</li>
<li>#### We create a helper function to create a list with one entry (bit) set to a value and all others set to 0.</li>
<li>#### We create 101 bins for the 100 threshold values between 0 and 1.</li>
<li>#### Now, for each similarity score, we can compute the false 
positives. We do this by adding each similarity score to the appropriate
 bin of the vector. Then we remove true positives from the vector by 
using the gold standard data.</li>
<li><h4><a id="user-content-we-define-functions-for-computing-false-positive-and-negative-and-true-positives-for-a-given-threshold" class="anchor" href="#we-define-functions-for-computing-false-positive-and-negative-and-true-positives-for-a-given-threshold" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We define functions for computing false positive and negative and true positives, for a given threshold.</h4>

<p>from pyspark.accumulators import AccumulatorParam
class VectorAccumulatorParam(AccumulatorParam):
    # Initialize the VectorAccumulator to 0
    def zero(self, value):
        return [0] * len(value)</p>

<pre><code># Add two VectorAccumulator variables
def addInPlace(self, val1, val2):
    for i in xrange(len(val1)):
        val1[i] += val2[i]
    return val1
</code></pre>

<h1><a id="user-content-return-a-list-with-entry-x-set-to-value-and-all-other-entries-set-to-0" class="anchor" href="#return-a-list-with-entry-x-set-to-value-and-all-other-entries-set-to-0" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Return a list with entry x set to value and all other entries set to 0</h1>

<p>def set_bit(x, value, length):
    bits = []
    for y in xrange(length):
        if (x == y):
          bits.append(value)
        else:
          bits.append(0)
    return bits</p>

<h1><a id="user-content-pre-bin-counts-of-false-positives-for-different-threshold-ranges" class="anchor" href="#pre-bin-counts-of-false-positives-for-different-threshold-ranges" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Pre-bin counts of false positives for different threshold ranges</h1>

<p>BINS = 101
nthresholds = 100
def bin(similarity):
    return int(similarity * nthresholds)</p>

<h1><a id="user-content-fpcountsi--number-of-entries-possible-false-positives-where-binsimilarity--i" class="anchor" href="#fpcountsi--number-of-entries-possible-false-positives-where-binsimilarity--i" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>fpCounts[i] = number of entries (possible false positives) where bin(similarity) == i</h1>

<p>zeros = [0] * BINS
fpCounts = sc.accumulator(zeros, VectorAccumulatorParam())</p>

<p>def add_element(score):
    global fpCounts
    b = bin(score)
    fpCounts += set_bit(b, 1, BINS)</p>

<p>simsFullValuesRDD.foreach(add_element)</p>

<h1><a id="user-content-remove-true-positives-from-fp-counts" class="anchor" href="#remove-true-positives-from-fp-counts" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Remove true positives from FP counts</h1>

<p>def sub_element(score):
    global fpCounts
    b = bin(score)
    fpCounts += set_bit(b, -1, BINS)</p>

<p>trueDupSimsRDD.foreach(sub_element)</p>

<p>def falsepos(threshold):
    fpList = fpCounts.value
    return sum([fpList[b] for b in range(0, BINS) if float(b) / nthresholds &gt;= threshold])</p>

<p>def falseneg(threshold):
    return trueDupSimsRDD.filter(lambda x: x &lt; threshold).count()</p>

<p>def truepos(threshold):
    return trueDupSimsRDD.count() - falsenegDict[threshold]</p></li>
</ul>

<h3><a id="user-content-5b-precision-recall-and-f-measures" class="anchor" href="#5b-precision-recall-and-f-measures" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(5b) Precision, Recall, and F-measures</strong></h3>

<h4><a id="user-content-we-define-functions-so-that-we-can-compute-the-precision-recall-and-f-measure-as-a-function-of-threshold-value" class="anchor" href="#we-define-functions-so-that-we-can-compute-the-precision-recall-and-f-measure-as-a-function-of-threshold-value" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We define functions so that we can compute the <a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision</a>, <a href="https://en.wikipedia.org/wiki/Precision_and_recall">Recall</a>, and <a href="https://en.wikipedia.org/wiki/Precision_and_recall#F-measure">F-measure</a> as a function of threshold value:</h4>

<ul>
<li>#### Precision = true-positives / (true-positives + false-positives)</li>
<li>#### Recall = true-positives / (true-positives + false-negatives)</li>
<li><h4><a id="user-content-f-measure--2-x-recall-x-precision--recall--precision" class="anchor" href="#f-measure--2-x-recall-x-precision--recall--precision" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>F-measure = 2 x Recall x Precision / (Recall + Precision)</h4>

<h1><a id="user-content-precision--true-positives--true-positives--false-positives" class="anchor" href="#precision--true-positives--true-positives--false-positives" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Precision = true-positives / (true-positives + false-positives)</h1>

<h1><a id="user-content-recall--true-positives--true-positives--false-negatives" class="anchor" href="#recall--true-positives--true-positives--false-negatives" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Recall = true-positives / (true-positives + false-negatives)</h1>

<h1><a id="user-content-f-measure--2-x-recall-x-precision--recall--precision-1" class="anchor" href="#f-measure--2-x-recall-x-precision--recall--precision-1" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>F-measure = 2 x Recall x Precision / (Recall + Precision)</h1>

<p>def precision(threshold):
    tp = trueposDict[threshold]
    return float(tp) / (tp + falseposDict[threshold])</p>

<p>def recall(threshold):
    tp = trueposDict[threshold]
    return float(tp) / (tp + falsenegDict[threshold])</p>

<p>def fmeasure(threshold):
    r = recall(threshold)
    p = precision(threshold)
    return 2 * r * p / (r + p)</p></li>
</ul>

<h3><a id="user-content-5c-line-plots" class="anchor" href="#5c-line-plots" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a><strong>(5c) Line Plots</strong></h3>

<h4><a id="user-content-we-can-make-line-plots-of-precision-recall-and-f-measure-as-a-function-of-threshold-value-for-thresholds-between-00-and-10--you-can-change-nthresholds-above-in-part-5a-to-change-the-threshold-values-to-plot" class="anchor" href="#we-can-make-line-plots-of-precision-recall-and-f-measure-as-a-function-of-threshold-value-for-thresholds-between-00-and-10--you-can-change-nthresholds-above-in-part-5a-to-change-the-threshold-values-to-plot" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>We
 can make line plots of precision, recall, and F-measure as a function 
of threshold value, for thresholds between 0.0 and 1.0.  You can change <code>nthresholds</code> (above in part <strong>(5a)</strong>) to change the threshold values to plot.</h4>

<pre><code>thresholds = [float(n) / nthresholds for n in range(0, nthresholds)]
falseposDict = dict([(t, falsepos(t)) for t in thresholds])
falsenegDict = dict([(t, falseneg(t)) for t in thresholds])
trueposDict = dict([(t, truepos(t)) for t in thresholds])

precisions = [precision(t) for t in thresholds]
recalls = [recall(t) for t in thresholds]
fmeasures = [fmeasure(t) for t in thresholds]

print precisions[0], fmeasures[0]
assert (abs(precisions[0] - 0.000532546802671) &lt; 0.0000001)
assert (abs(fmeasures[0] - 0.00106452669505) &lt; 0.0000001)


fig = plt.figure()
plt.plot(thresholds, precisions)
plt.plot(thresholds, recalls)
plt.plot(thresholds, fmeasures)
plt.legend(['Precision', 'Recall', 'F-measure'])
pass
</code></pre>

<h3><a id="user-content-discussion" class="anchor" href="#discussion" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>Discussion</h3>

<h4><a id="user-content-state-of-the-art-tools-can-get-an-f-measure-of-about-60-on-this-dataset-in-this-lab-exercise-our-best-f-measure-is-closer-to-40-look-at-some-examples-of-errors-both-false-positives-and-false-negatives-and-think-about-what-went-wrong" class="anchor" href="#state-of-the-art-tools-can-get-an-f-measure-of-about-60-on-this-dataset-in-this-lab-exercise-our-best-f-measure-is-closer-to-40-look-at-some-examples-of-errors-both-false-positives-and-false-negatives-and-think-about-what-went-wrong" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>State-of-the-art
 tools can get an F-measure of about 60% on this dataset. In this lab 
exercise, our best F-measure is closer to 40%. Look at some examples of 
errors (both False Positives and False Negatives) and think about what 
went wrong.</h4>

<h3><a id="user-content-there-are-several-ways-we-might-improve-our-simple-classifier-including" class="anchor" href="#there-are-several-ways-we-might-improve-our-simple-classifier-including" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>There are several ways we might improve our simple classifier, including:</h3>

<h4><a id="user-content--using-additional-attributes" class="anchor" href="#-using-additional-attributes" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>* Using additional attributes</h4>

<h4><a id="user-content--performing-better-featurization-of-our-textual-data-eg-stemming-n-grams-etc" class="anchor" href="#-performing-better-featurization-of-our-textual-data-eg-stemming-n-grams-etc" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>* Performing better featurization of our textual data (e.g., stemming, n-grams, etc.)</h4>

<h4><a id="user-content--using-different-similarity-functions" class="anchor" href="#-using-different-similarity-functions" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path></svg></a>* Using different similarity functions</h4>
</article>
  </div>

  </div>
  
</div>


  <a name="comments"></a>
  <div class="discussion-timeline gist-discussion-timeline js-quote-selection-container ">
    <div class="js-discussion js-socket-channel" data-channel="marianboda/469651cbcda0d92f02ee:marked-as-read:23672941">
      




<!-- Rendered timeline since 2015-11-06 02:54:14 -->
<div id="partial-timeline-marker" class="js-timeline-marker js-socket-channel js-updatable-content" data-channel="marianboda/469651cbcda0d92f02ee:gist:23672941" data-url="/marianboda/469651cbcda0d92f02ee/show_partial?partial=gist%2Ftimeline_marker&amp;since=1446807254" data-last-modified="Fri, 06 Nov 2015 10:54:14 GMT">
</div>


      <div class="discussion-timeline-actions">
          <div class="signed-out-comment">
    <a href="https://gist.github.com/join?source=comment-gist" class="btn btn-primary" rel="nofollow">Sign up for free</a>
    <strong>to join this conversation on GitHub</strong>.
    Already have an account?
    <a href="https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Fmarianboda%2F469651cbcda0d92f02ee" rel="nofollow">Sign in to comment</a>
</div>

      </div>
    </div>
  </div>
</div>
  </div>

  <div class="modal-backdrop"></div>
</div><!-- /.container -->

    </div><!-- /.gist-pjax-container -->
  </div>

    </div>

        <div class="container">
  <div class="site-footer" role="contentinfo">
    <ul class="site-footer-links right">
        <li><a href="https://status.github.com/" data-ga-click="Footer, go to status, text:status">Status</a></li>
      <li><a href="https://developer.github.com/" data-ga-click="Footer, go to api, text:api">API</a></li>
      <li><a href="https://training.github.com/" data-ga-click="Footer, go to training, text:training">Training</a></li>
      <li><a href="https://shop.github.com/" data-ga-click="Footer, go to shop, text:shop">Shop</a></li>
        <li><a href="https://github.com/blog" data-ga-click="Footer, go to blog, text:blog">Blog</a></li>
        <li><a href="https://github.com/about" data-ga-click="Footer, go to about, text:about">About</a></li>
        <li><a href="https://github.com/pricing" data-ga-click="Footer, go to pricing, text:pricing">Pricing</a></li>

    </ul>

    <a href="https://github.com/" aria-label="Homepage">
      <svg aria-hidden="true" class="octicon octicon-mark-github" height="24" role="img" title="GitHub " version="1.1" viewBox="0 0 16 16" width="24"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59 0.4 0.07 0.55-0.17 0.55-0.38 0-0.19-0.01-0.82-0.01-1.49-2.01 0.37-2.53-0.49-2.69-0.94-0.09-0.23-0.48-0.94-0.82-1.13-0.28-0.15-0.68-0.52-0.01-0.53 0.63-0.01 1.08 0.58 1.23 0.82 0.72 1.21 1.87 0.87 2.33 0.66 0.07-0.52 0.28-0.87 0.51-1.07-1.78-0.2-3.64-0.89-3.64-3.95 0-0.87 0.31-1.59 0.82-2.15-0.08-0.2-0.36-1.02 0.08-2.12 0 0 0.67-0.21 2.2 0.82 0.64-0.18 1.32-0.27 2-0.27 0.68 0 1.36 0.09 2 0.27 1.53-1.04 2.2-0.82 2.2-0.82 0.44 1.1 0.16 1.92 0.08 2.12 0.51 0.56 0.82 1.27 0.82 2.15 0 3.07-1.87 3.75-3.65 3.95 0.29 0.25 0.54 0.73 0.54 1.48 0 1.07-0.01 1.93-0.01 2.2 0 0.21 0.15 0.46 0.55 0.38C13.71 14.53 16 11.53 16 8 16 3.58 12.42 0 8 0z"></path></svg>
</a>
    <ul class="site-footer-links">
      <li>Â© 2016 <span title="0.04924s from github-fe119-cp1-prd.iad.github.net">GitHub</span>, Inc.</li>
        <li><a href="https://github.com/site/terms" data-ga-click="Footer, go to terms, text:terms">Terms</a></li>
        <li><a href="https://github.com/site/privacy" data-ga-click="Footer, go to privacy, text:privacy">Privacy</a></li>
        <li><a href="https://github.com/security" data-ga-click="Footer, go to security, text:security">Security</a></li>
        <li><a href="https://github.com/contact" data-ga-click="Footer, go to contact, text:contact">Contact</a></li>
        <li><a href="https://help.github.com/" data-ga-click="Footer, go to help, text:help">Help</a></li>
    </ul>
  </div>
</div>



    
    
    

    <div id="ajax-error-message" class="flash flash-error">
      <svg aria-hidden="true" class="octicon octicon-alert" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M15.72 12.5l-6.85-11.98C8.69 0.21 8.36 0.02 8 0.02s-0.69 0.19-0.87 0.5l-6.85 11.98c-0.18 0.31-0.18 0.69 0 1C0.47 13.81 0.8 14 1.15 14h13.7c0.36 0 0.69-0.19 0.86-0.5S15.89 12.81 15.72 12.5zM9 12H7V10h2V12zM9 9H7V5h2V9z"></path></svg>
      <button type="button" class="flash-close js-flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
        <svg aria-hidden="true" class="octicon octicon-x" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M7.48 8l3.75 3.75-1.48 1.48-3.75-3.75-3.75 3.75-1.48-1.48 3.75-3.75L0.77 4.25l1.48-1.48 3.75 3.75 3.75-3.75 1.48 1.48-3.75 3.75z"></path></svg>
      </button>
      Something went wrong with that request. Please try again.
    </div>


      
      <script crossorigin="anonymous" integrity="sha256-7lIbjp+srGj/J+k/w64PjtgR17+eQ06E9LnqIneAsIQ=" src="lab3.md%20%C2%B7%20GitHub_files/frameworks-ee521b8e9facac68ff27e93fc3ae0f8ed811d7bf9e434e84f4.js"></script>
      <script async="async" crossorigin="anonymous" integrity="sha256-Kc/69UqecjIY/K6vNSx8RViE6xhDQi5C4ihKOqGqaxk=" src="lab3.md%20%C2%B7%20GitHub_files/github-29cffaf54a9e723218fcaeaf352c7c455884eb1843422e42e2284a.js"></script>
      
      
      
    <div class="js-stale-session-flash stale-session-flash flash flash-warn flash-banner hidden">
      <svg aria-hidden="true" class="octicon octicon-alert" height="16" role="img" version="1.1" viewBox="0 0 16 16" width="16"><path d="M15.72 12.5l-6.85-11.98C8.69 0.21 8.36 0.02 8 0.02s-0.69 0.19-0.87 0.5l-6.85 11.98c-0.18 0.31-0.18 0.69 0 1C0.47 13.81 0.8 14 1.15 14h13.7c0.36 0 0.69-0.19 0.86-0.5S15.89 12.81 15.72 12.5zM9 12H7V10h2V12zM9 9H7V5h2V9z"></path></svg>
      <span class="signed-in-tab-flash">You signed in with another tab or window. <a href="">Reload</a> to refresh your session.</span>
      <span class="signed-out-tab-flash">You signed out in another tab or window. <a href="">Reload</a> to refresh your session.</span>
    </div>
    <div class="facebox" id="facebox" style="display:none;">
  <div class="facebox-popup">
    <div class="facebox-content" role="dialog" aria-labelledby="facebox-header" aria-describedby="facebox-description">
    </div>
    <button type="button" class="facebox-close js-facebox-close" aria-label="Close modal">
      <svg aria-hidden="true" class="octicon octicon-x" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path d="M7.48 8l3.75 3.75-1.48 1.48-3.75-3.75-3.75 3.75-1.48-1.48 3.75-3.75L0.77 4.25l1.48-1.48 3.75 3.75 3.75-3.75 1.48 1.48-3.75 3.75z"></path></svg>
    </button>
  </div>
</div>

  


</body></html>